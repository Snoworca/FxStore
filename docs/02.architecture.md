# FxStore 파일 구조 및 알고리즘 심층 구현 가이드

> **문서 버전:** 1.0  
> **대상 독자:** FxStore 구현 개발자  
> **전제 조건:** SRS v0.3, API 명세서 (Final), 파일 구조·알고리즘·구현 방법 문서 숙지

---

## 목차

1. [설계 철학과 핵심 불변식](#1-설계-철학과-핵심-불변식)
2. [바이트 레벨 파일 구조 상세](#2-바이트-레벨-파일-구조-상세)
3. [메모리 모델과 캐싱 전략](#3-메모리-모델과-캐싱-전략)
4. [B+Tree 알고리즘 심층 분석](#4-btree-알고리즘-심층-분석)
5. [Order-Statistic Tree 구현 상세](#5-order-statistic-tree-구현-상세)
6. [Deque 시퀀스 관리](#6-deque-시퀀스-관리)
7. [Catalog/State 분리 아키텍처](#7-catalogstate-분리-아키텍처)
8. [커밋 프로토콜과 크래시 복구](#8-커밋-프로토콜과-크래시-복구)
9. [코덱 시스템 구현](#9-코덱-시스템-구현)
10. [컴팩션 알고리즘](#10-컴팩션-알고리즘)
11. [동시성과 락 전략](#11-동시성과-락-전략)
12. [성능 최적화 기법](#12-성능-최적화-기법)
13. [테스트 및 검증 전략](#13-테스트-및-검증-전략)
14. [구현 로드맵](#14-구현-로드맵)

---

## 1. 설계 철학과 핵심 불변식

### 1.1 설계 철학

FxStore의 설계는 다음 원칙을 따릅니다:

**원칙 1: 단순성 우선 (Simplicity First)**
- 복잡한 최적화보다 정확성과 유지보수성을 우선
- 온라인 컴팩션, 다중 writer 등 고급 기능은 의도적으로 제외
- append-only 할당으로 공간 관리 복잡도 최소화

**원칙 2: 크래시 일관성 (Crash Consistency)**
- 모든 공개 상태 변경은 CommitHeader 슬롯 교체로만 발생
- COW(Copy-on-Write)로 기존 데이터 절대 덮어쓰지 않음
- 어떤 시점에 크래시가 발생해도 마지막 커밋 상태로 복구 가능

**원칙 3: Java 컬렉션 호환 (Collection Compatibility)**
- NavigableMap, NavigableSet, List, Deque 인터페이스 완전 구현
- 사용자에게 트랜잭션/스냅샷 객체 노출하지 않음
- 내부 복잡성을 API 뒤에 숨김

**원칙 4: 확장 가능한 타입 시스템 (Extensible Type System)**
- 코덱 기반 직렬화로 임의 타입 지원
- 내장 타입(I64, F64, STRING, BYTES)과 사용자 코덱 공존
- 버전 관리로 스키마 진화 지원

### 1.2 핵심 불변식 (Invariants)

시스템이 항상 유지해야 하는 불변식들입니다. 이들이 깨지면 데이터 손상입니다.

```
INV-1: CommitHeader의 seqNo는 항상 단조 증가한다.
       ∀ commit c1, c2: c1.time < c2.time → c1.seqNo < c2.seqNo

INV-2: 커밋된 헤더가 가리키는 모든 페이지/레코드는 디스크에 존재한다.
       ∀ pageId ∈ reachable(header): pageId * pageSize < fileSize

INV-3: Catalog의 name은 유일하다.
       ∀ e1, e2 ∈ Catalog: e1.name = e2.name → e1 = e2

INV-4: State의 collectionId는 유일하다.
       ∀ s1, s2 ∈ State: s1.collectionId = s2.collectionId → s1 = s2

INV-5: collectionId는 재사용되지 않는다 (삭제 후에도).
       nextCollectionId는 항상 증가만 한다.

INV-6: B+Tree의 키는 정렬 순서를 유지한다.
       ∀ leaf: ∀ i < j: compare(leaf.keys[i], leaf.keys[j]) < 0

INV-7: OST의 subtreeCount 합은 정확하다.
       ∀ internal node n: sum(n.subtreeCounts) = totalElements(n)

INV-8: Deque의 headSeq ≤ tailSeq + 1이다.
       headSeq > tailSeq + 1이면 size가 음수가 되는 모순

INV-9: allocTail은 항상 증가만 한다 (컴팩션 제외).
       모든 할당은 append-only
```

### 1.3 상태 전이 다이어그램

```
                              ┌─────────────────┐
                              │   File Closed   │
                              └────────┬────────┘
                                       │ open()
                                       ▼
                              ┌─────────────────┐
                              │  Header Select  │
                              │  (A or B by     │
                              │   seqNo)        │
                              └────────┬────────┘
                                       │
              ┌────────────────────────┴────────────────────────┐
              │                                                 │
              ▼                                                 ▼
    ┌─────────────────┐                               ┌─────────────────┐
    │   AUTO Mode     │                               │   BATCH Mode    │
    │                 │                               │                 │
    │ 연산마다 커밋    │                               │ pending 루트    │
    │ 헤더 A↔B 교체   │                               │ 누적             │
    └────────┬────────┘                               └────────┬────────┘
             │                                                 │
             │ 각 연산                          commit()       │ rollback()
             ▼                                    │            │
    ┌─────────────────┐                          ▼            ▼
    │ COW 수정        │                   ┌───────────┐ ┌───────────┐
    │ → 새 페이지     │                   │ 헤더 교체  │ │ pending   │
    │ → 헤더 교체     │                   │ 공개      │ │ 폐기      │
    │ → 공개         │                   └───────────┘ └───────────┘
    └─────────────────┘

                              close()
                                 │
                                 ▼
                        ┌─────────────────┐
                        │  OnClosePolicy  │
                        │  ERROR/COMMIT/  │
                        │  ROLLBACK       │
                        └─────────────────┘
```

---

## 2. 바이트 레벨 파일 구조 상세

### 2.1 전체 파일 레이아웃

```
Offset (hex)    Size        Content
────────────────────────────────────────────────────────────
0x0000_0000     4096        Superblock
0x0000_1000     4096        CommitHeader Slot A
0x0000_2000     4096        CommitHeader Slot B
0x0000_3000     variable    Allocation Area
                            ├── Pages (pageSize aligned)
                            └── Records (8-byte aligned)
```

### 2.2 Superblock 상세 레이아웃 (4096 bytes)

```
Offset  Size    Type        Field               Value/Description
────────────────────────────────────────────────────────────────────
0x00    8       char[8]     magic               "FXSTORE\0" (0x46585354 4F524500)
0x08    4       u32         formatVersion       1 (current)
0x0C    4       u32         pageSize            4096 | 8192 | 16384
0x10    8       u64         featureFlags        bit 0: CRC enabled
                                                bit 1: mmap recommended
                                                bit 2-63: reserved (0)
0x18    8       u64         createdAtEpochMs    Unix timestamp in milliseconds
0x20    4056    byte[]      reserved            All zeros (0x00)
0xFFC   4       u32         crc32c              CRC of bytes [0x00, 0xFFC)
────────────────────────────────────────────────────────────────────
Total: 4096 bytes
```

**CRC 계산 범위:**
```java
// Superblock CRC 계산
byte[] superblockData = new byte[4092];  // offset 0 ~ 4091
int crc = CRC32C.compute(superblockData, 0, 4092);
// crc를 offset 4092에 little-endian으로 기록
```

**검증 코드:**
```java
boolean verifySuperblock(byte[] data) {
    // 1. Magic 검증
    if (!Arrays.equals(Arrays.copyOf(data, 8), "FXSTORE\0".getBytes())) {
        return false;
    }
    
    // 2. Format version 검증
    int version = readU32LE(data, 8);
    if (version != 1) {
        return false;
    }
    
    // 3. Page size 검증
    int pageSize = readU32LE(data, 12);
    if (pageSize != 4096 && pageSize != 8192 && pageSize != 16384) {
        return false;
    }
    
    // 4. CRC 검증
    int storedCrc = readU32LE(data, 4092);
    int computedCrc = CRC32C.compute(data, 0, 4092);
    return storedCrc == computedCrc;
}
```

### 2.3 CommitHeader 상세 레이아웃 (4096 bytes)

```
Offset  Size    Type        Field                   Description
────────────────────────────────────────────────────────────────────
0x00    8       char[8]     magic                   "FXHDR\0\0\0" (0x46584844 52000000)
0x08    4       u32         headerVersion           1 (current)
0x0C    4       u32         _padding1               Reserved, must be 0
0x10    8       u64         seqNo                   Monotonically increasing
0x18    8       u64         committedFlags          bit 0: SYNC durability
                                                    bit 1-63: reserved
0x20    8       u64         allocTail               Next free byte offset
0x28    8       u64         catalogRootPageId       0 if empty
0x30    8       u64         stateRootPageId         0 if empty
0x38    8       u64         nextCollectionId        Next ID to assign
0x40    8       u64         commitEpochMs           Commit timestamp
0x48    4020    byte[]      reserved                All zeros
0xFFC   4       u32         crc32c                  CRC of bytes [0x00, 0xFFC)
────────────────────────────────────────────────────────────────────
Total: 4096 bytes
```

**헤더 선택 알고리즘:**
```java
CommitHeader selectHeader(byte[] slotA, byte[] slotB) {
    boolean aValid = verifyHeaderCrc(slotA);
    boolean bValid = verifyHeaderCrc(slotB);
    
    if (!aValid && !bValid) {
        throw new FxException("No valid header", CORRUPTION);
    }
    
    if (!aValid) return parseHeader(slotB, 'B');
    if (!bValid) return parseHeader(slotA, 'A');
    
    // 둘 다 유효하면 seqNo가 큰 것 선택
    long seqA = readU64LE(slotA, 0x10);
    long seqB = readU64LE(slotB, 0x10);
    
    return seqA >= seqB 
        ? parseHeader(slotA, 'A') 
        : parseHeader(slotB, 'B');
}
```

### 2.4 Page 공통 헤더 (32 bytes)

```
Offset  Size    Type        Field               Description
────────────────────────────────────────────────────────────────────
0x00    4       char[4]     pageMagic           "FXPG" (0x46585047)
0x04    2       u16         pageType            1=BTREE_INTERNAL
                                                2=BTREE_LEAF
                                                3=OST_INTERNAL
                                                4=OST_LEAF
0x06    2       u16         pageFlags           bit 0: compressed (future)
                                                bit 1-15: reserved
0x08    8       u64         pageId              This page's ID
0x10    8       u64         lsnOrSeq            Debug/verification
0x18    4       u32         payloadCrc32c       CRC of payload
0x1C    4       u32         reserved            Alignment padding
────────────────────────────────────────────────────────────────────
Header: 32 bytes
Payload: pageSize - 32 bytes
```

### 2.5 ValueRecord 상세 레이아웃

```
Offset  Size        Type        Field           Description
────────────────────────────────────────────────────────────────────
0x00    4           char[4]     recMagic        "FXRC" (0x46585243)
0x04    2           u16         recType         1=VALUE
                                                2=OVERFLOW
                                                3=CODEC_META (future)
0x06    2           u16         recFlags        bit 0: compressed
                                                bit 1-15: reserved
0x08    1-10        varint      payloadLen      LEB128 encoded length
var     4           u32         payloadCrc32c   CRC of payload bytes
var     payloadLen  byte[]      payload         Actual data
────────────────────────────────────────────────────────────────────
```

**Varint (LEB128) 인코딩:**
```java
// 인코딩
byte[] encodeVarint(long value) {
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    while (value > 0x7F) {
        out.write((int)(value & 0x7F) | 0x80);
        value >>>= 7;
    }
    out.write((int)value);
    return out.toByteArray();
}

// 디코딩
long decodeVarint(byte[] data, int offset, int[] bytesRead) {
    long result = 0;
    int shift = 0;
    int pos = offset;
    
    while (true) {
        byte b = data[pos++];
        result |= (long)(b & 0x7F) << shift;
        if ((b & 0x80) == 0) break;
        shift += 7;
        if (shift > 63) throw new IllegalStateException("Varint too long");
    }
    
    bytesRead[0] = pos - offset;
    return result;
}
```

### 2.6 BTREE_LEAF Payload 상세

```
Payload Layout (within page, after 32-byte header):
────────────────────────────────────────────────────────────────────
                    Offset from payload start
Offset  Size        Field               Description
────────────────────────────────────────────────────────────────────
0x00    2           entryCount          Number of entries
0x02    2           freeSpaceOffset     First free byte (from payload start)
0x04    8           nextLeafPageId      0 if last leaf
0x0C    2*N         slots[N]            Entry offsets (u16 each)
...     variable    [free space]        Grows toward entries
...     variable    entries[]           Grows backward from end
────────────────────────────────────────────────────────────────────

Entry Layout (at slots[i] offset):
────────────────────────────────────────────────────────────────────
0x00    varint      keyLen              Key byte length
var     keyLen      keyBytes            Key data
var     8           valueRef            Record offset (u64)
var     2           entryFlags          bit 0: tombstone (future)
var     2           reserved            Alignment
────────────────────────────────────────────────────────────────────
```

**Slotted Page 삽입 알고리즘:**
```java
class SlottedPage {
    byte[] data;
    int payloadStart = 32;  // After page header
    
    int getEntryCount() {
        return readU16LE(data, payloadStart);
    }
    
    int getFreeSpaceOffset() {
        return readU16LE(data, payloadStart + 2);
    }
    
    void setFreeSpaceOffset(int offset) {
        writeU16LE(data, payloadStart + 2, offset);
    }
    
    int getSlot(int index) {
        return readU16LE(data, payloadStart + 12 + index * 2);
    }
    
    void setSlot(int index, int offset) {
        writeU16LE(data, payloadStart + 12 + index * 2, offset);
    }
    
    // 삽입 가능한 공간 계산
    int availableSpace() {
        int slotsEnd = payloadStart + 12 + getEntryCount() * 2;
        int entriesStart = getFreeSpaceOffset();
        return entriesStart - slotsEnd - 2;  // -2 for new slot
    }
    
    // 정렬된 위치에 엔트리 삽입
    void insertEntry(int position, byte[] entryBlob) {
        int count = getEntryCount();
        int entrySize = entryBlob.length;
        
        // 새 엔트리를 뒤쪽에 기록
        int newEntryOffset = getFreeSpaceOffset() - entrySize;
        System.arraycopy(entryBlob, 0, data, 
                         payloadStart + newEntryOffset, entrySize);
        setFreeSpaceOffset(newEntryOffset);
        
        // 슬롯 배열에서 position 이후를 shift
        for (int i = count; i > position; i--) {
            setSlot(i, getSlot(i - 1));
        }
        setSlot(position, newEntryOffset);
        
        // 엔트리 개수 증가
        writeU16LE(data, payloadStart, count + 1);
    }
}
```

### 2.7 BTREE_INTERNAL Payload 상세

```
Payload Layout:
────────────────────────────────────────────────────────────────────
Offset  Size        Field               Description
────────────────────────────────────────────────────────────────────
0x00    2           level               Tree level (leaf=0)
0x02    2           keyCount            Number of separator keys
0x04    2           childCount          keyCount + 1
0x06    2           freeSpaceOffset     First free byte
0x08    8*C         children[C]         Child page IDs (u64 each)
var     2*K         slots[K]            Key blob offsets
...     variable    key blobs           keyLen(var) + keyBytes
────────────────────────────────────────────────────────────────────
```

**Internal 노드 검색:**
```java
// key가 들어갈 자식 인덱스 찾기
int findChildIndex(Page internal, byte[] key, Comparator<byte[]> cmp) {
    int keyCount = internal.getKeyCount();
    
    // Binary search for insertion point
    int lo = 0, hi = keyCount;
    while (lo < hi) {
        int mid = (lo + hi) / 2;
        byte[] midKey = internal.getKey(mid);
        int c = cmp.compare(key, midKey);
        if (c < 0) {
            hi = mid;
        } else {
            lo = mid + 1;
        }
    }
    
    return lo;  // children[lo]가 대상 자식
}
```

---

## 3. 메모리 모델과 캐싱 전략

### 3.1 Storage 추상화 계층

```java
/**
 * 저장소 추상화 - 파일과 메모리 모드를 통일
 */
public interface Storage extends AutoCloseable {
    /**
     * 지정 오프셋에서 데이터 읽기
     * @throws FxException(IO) 실패 시
     */
    void read(long offset, byte[] buffer, int bufOffset, int length);
    
    /**
     * 지정 오프셋에 데이터 쓰기
     * append-only 정책: offset >= 현재 파일 크기이거나,
     * 헤더 영역(0~12288)만 덮어쓰기 허용
     */
    void write(long offset, byte[] buffer, int bufOffset, int length);
    
    /**
     * 버퍼를 디스크에 동기화
     * @param metadata true면 파일 메타데이터도 동기화
     */
    void force(boolean metadata);
    
    /**
     * 현재 저장소 크기
     */
    long size();
    
    /**
     * 크기 확장 (truncate는 compaction 외에 사용하지 않음)
     */
    void extend(long newSize);
}

/**
 * 파일 기반 구현
 */
public class FileStorage implements Storage {
    private final FileChannel channel;
    private final FileLock lock;  // PROCESS 모드에서만
    
    @Override
    public void read(long offset, byte[] buffer, int bufOffset, int length) {
        ByteBuffer bb = ByteBuffer.wrap(buffer, bufOffset, length);
        int totalRead = 0;
        while (totalRead < length) {
            int read = channel.read(bb, offset + totalRead);
            if (read < 0) throw new FxException("Unexpected EOF", IO);
            totalRead += read;
        }
    }
    
    @Override
    public void force(boolean metadata) {
        channel.force(metadata);
    }
}

/**
 * 메모리 기반 구현 (테스트 및 임시 용도)
 */
public class MemoryStorage implements Storage {
    private ByteBuffer buffer;
    private final long limitBytes;
    
    @Override
    public void write(long offset, byte[] data, int bufOffset, int length) {
        ensureCapacity(offset + length);
        buffer.position((int)offset);
        buffer.put(data, bufOffset, length);
    }
    
    private void ensureCapacity(long required) {
        if (required > limitBytes) {
            throw new FxException("Memory limit exceeded", OUT_OF_MEMORY);
        }
        if (required > buffer.capacity()) {
            // 2배씩 확장
            int newCap = Math.max((int)required, buffer.capacity() * 2);
            ByteBuffer newBuf = ByteBuffer.allocate(newCap);
            buffer.flip();
            newBuf.put(buffer);
            buffer = newBuf;
        }
    }
    
    @Override
    public void force(boolean metadata) {
        // No-op for memory
    }
}
```

### 3.2 페이지 캐시 설계

```java
/**
 * LRU 기반 페이지 캐시
 * 
 * 설계 결정:
 * - 읽기 캐시만 (쓰기는 항상 새 페이지에)
 * - 페이지 ID를 키로 사용
 * - dirty 페이지 개념 없음 (COW이므로)
 */
public class PageCache {
    private final int maxPages;
    private final int pageSize;
    private final LinkedHashMap<Long, byte[]> cache;
    
    public PageCache(long cacheBytes, int pageSize) {
        this.pageSize = pageSize;
        this.maxPages = (int)(cacheBytes / pageSize);
        
        // accessOrder=true로 LRU 동작
        this.cache = new LinkedHashMap<>(maxPages, 0.75f, true) {
            @Override
            protected boolean removeEldestEntry(Map.Entry<Long, byte[]> eldest) {
                return size() > maxPages;
            }
        };
    }
    
    public byte[] get(long pageId) {
        return cache.get(pageId);
    }
    
    public void put(long pageId, byte[] pageData) {
        // 캐시에 저장 전 복사 (불변성 보장)
        byte[] copy = Arrays.copyOf(pageData, pageData.length);
        cache.put(pageId, copy);
    }
    
    /**
     * 커밋 후 invalidation은 필요 없음
     * COW이므로 기존 페이지 ID의 내용은 변하지 않음
     * 새 페이지는 새 ID를 가짐
     */
    public void invalidate(long pageId) {
        cache.remove(pageId);
    }
    
    public void clear() {
        cache.clear();
    }
}
```

### 3.3 Allocator 구현

```java
/**
 * Append-only 할당자
 * 
 * 설계 결정:
 * - 단일 allocTail 포인터로 관리
 * - 페이지는 pageSize 정렬, 레코드는 8바이트 정렬
 * - 해제 없음 (컴팩션으로만 공간 회수)
 */
public class Allocator {
    private final Storage storage;
    private final int pageSize;
    private long allocTail;
    
    // BATCH 모드에서의 pending 상태
    private Long pendingAllocTail = null;
    
    public Allocator(Storage storage, int pageSize, long initialTail) {
        this.storage = storage;
        this.pageSize = pageSize;
        this.allocTail = initialTail;
    }
    
    /**
     * 현재 유효한 allocTail (BATCH pending 고려)
     */
    public long effectiveTail() {
        return pendingAllocTail != null ? pendingAllocTail : allocTail;
    }
    
    /**
     * 새 페이지 할당
     * @return 할당된 pageId
     */
    public long allocPage() {
        long tail = effectiveTail();
        long alignedOffset = alignUp(tail, pageSize);
        long newTail = alignedOffset + pageSize;
        
        // 파일 확장
        if (newTail > storage.size()) {
            storage.extend(newTail);
        }
        
        if (pendingAllocTail != null) {
            pendingAllocTail = newTail;
        } else {
            allocTail = newTail;
        }
        
        return alignedOffset / pageSize;
    }
    
    /**
     * 새 레코드 할당
     * @param totalSize 헤더 + payload 전체 크기
     * @return 할당된 오프셋
     */
    public long allocRecord(int totalSize) {
        long tail = effectiveTail();
        long alignedOffset = alignUp(tail, 8);
        long newTail = alignedOffset + totalSize;
        
        if (newTail > storage.size()) {
            storage.extend(newTail);
        }
        
        if (pendingAllocTail != null) {
            pendingAllocTail = newTail;
        } else {
            allocTail = newTail;
        }
        
        return alignedOffset;
    }
    
    /**
     * BATCH 모드 진입
     */
    public void beginBatch() {
        pendingAllocTail = allocTail;
    }
    
    /**
     * BATCH 커밋
     */
    public void commitBatch() {
        if (pendingAllocTail != null) {
            allocTail = pendingAllocTail;
            pendingAllocTail = null;
        }
    }
    
    /**
     * BATCH 롤백
     * 이미 기록된 데이터는 dead로 남음
     */
    public void rollbackBatch() {
        pendingAllocTail = null;
    }
    
    private static long alignUp(long value, int alignment) {
        return (value + alignment - 1) & ~(alignment - 1);
    }
}
```

### 3.4 메모리 사용량 추정

```
컬렉션당 메모리 (핸들 객체):
- 기본 참조/메타데이터: ~100 bytes
- 캐시된 CollectionState: ~64 bytes
- 코덱 참조: ~32 bytes

페이지 캐시:
- 페이지당: pageSize bytes + ~50 bytes overhead
- 기본 64MiB → 약 16,000 페이지 (4K 기준)

Store 인스턴스:
- 기본 구조: ~500 bytes
- Allocator: ~100 bytes
- Header 사본: ~4,200 bytes
- Codec registry: 코덱 수 * ~200 bytes
```

---

## 4. B+Tree 알고리즘 심층 분석

### 4.1 B+Tree 파라미터 선택

```java
/**
 * B+Tree 차수 결정
 * 
 * pageSize = 4096, headerSize = 32, payloadSize = 4064
 * 
 * Internal 노드:
 *   children: 8 bytes each
 *   keys: variable (assume avg 20 bytes including length prefix)
 *   slots: 2 bytes each
 *   fixed overhead: 8 bytes
 *   
 *   Capacity = (payloadSize - 8) / (8 + 20 + 2) ≈ 135 keys
 *   → maxKeys = 128 (안전 마진)
 *   → minKeys = 64 (50%)
 *
 * Leaf 노드:
 *   entries: keyLen(var) + key + valueRef(8) + flags(4) ≈ avg 32 bytes
 *   slots: 2 bytes each
 *   fixed overhead: 12 bytes
 *   
 *   Capacity = (payloadSize - 12) / (32 + 2) ≈ 119 entries
 *   → maxEntries = 100 (안전 마진)
 *   → minEntries = 50 (50%)
 */
public class BPlusTreeConfig {
    public static final int MAX_INTERNAL_KEYS = 128;
    public static final int MIN_INTERNAL_KEYS = 64;
    public static final int MAX_LEAF_ENTRIES = 100;
    public static final int MIN_LEAF_ENTRIES = 50;
    
    // Split 위치 (중간)
    public static final int SPLIT_INTERNAL = 64;
    public static final int SPLIT_LEAF = 50;
}
```

### 4.2 COW B+Tree Find 알고리즘

```java
/**
 * B+Tree 검색
 * @return valueRef 또는 null (not found)
 */
public Long find(long rootPageId, byte[] key) {
    if (rootPageId == 0) return null;
    
    Page page = readPage(rootPageId);
    
    while (page.getType() == BTREE_INTERNAL) {
        int childIdx = findChildIndex(page, key);
        long childPageId = page.getChild(childIdx);
        page = readPage(childPageId);
    }
    
    // Leaf에서 binary search
    int idx = binarySearchLeaf(page, key);
    if (idx >= 0) {
        return page.getValueRef(idx);
    }
    return null;  // Not found
}

/**
 * Leaf에서 키 검색
 * @return 찾으면 인덱스, 못찾으면 -(insertionPoint + 1)
 */
private int binarySearchLeaf(Page leaf, byte[] key) {
    int lo = 0, hi = leaf.getEntryCount() - 1;
    
    while (lo <= hi) {
        int mid = (lo + hi) >>> 1;
        byte[] midKey = leaf.getKey(mid);
        int cmp = comparator.compare(key, midKey);
        
        if (cmp < 0) {
            hi = mid - 1;
        } else if (cmp > 0) {
            lo = mid + 1;
        } else {
            return mid;  // Found
        }
    }
    
    return -(lo + 1);  // Not found, insertion point = lo
}
```

### 4.3 COW B+Tree Insert 알고리즘 상세

```java
/**
 * B+Tree 삽입 (COW)
 * @return 새 루트 pageId
 */
public long insert(long rootPageId, byte[] key, long valueRef) {
    if (rootPageId == 0) {
        // 첫 삽입: 새 리프 생성
        return createSingleEntryLeaf(key, valueRef);
    }
    
    // 1. 검색 경로 수집
    List<PathFrame> path = new ArrayList<>();
    collectPath(rootPageId, key, path);
    
    // 2. 리프에 삽입 시도
    PathFrame leafFrame = path.get(path.size() - 1);
    Page leaf = leafFrame.page;
    
    int insertPos = findInsertPosition(leaf, key);
    
    // 중복 키 처리 (replace)
    if (insertPos >= 0 && insertPos < leaf.getEntryCount()) {
        byte[] existingKey = leaf.getKey(insertPos);
        if (comparator.compare(key, existingKey) == 0) {
            // Replace: 기존 키의 valueRef만 변경
            Page newLeaf = copyPage(leaf);
            newLeaf.setValueRef(insertPos, valueRef);
            return propagateCow(path, path.size() - 1, newLeaf);
        }
    }
    
    // 3. 공간 확인 및 삽입/분할
    byte[] entryBlob = encodeLeafEntry(key, valueRef);
    
    if (leaf.hasSpaceFor(entryBlob)) {
        // 공간 있음: 단순 삽입
        Page newLeaf = copyPage(leaf);
        newLeaf.insertEntry(insertPos, entryBlob);
        return propagateCow(path, path.size() - 1, newLeaf);
    } else {
        // 공간 없음: Split 필요
        return insertWithSplit(path, insertPos, key, valueRef);
    }
}

/**
 * 검색 경로 수집
 */
private void collectPath(long pageId, byte[] key, List<PathFrame> path) {
    Page page = readPage(pageId);
    
    while (page.getType() == BTREE_INTERNAL) {
        int childIdx = findChildIndex(page, key);
        path.add(new PathFrame(page, childIdx));
        
        long childPageId = page.getChild(childIdx);
        page = readPage(childPageId);
    }
    
    // 리프 추가 (childIdx는 의미 없음, -1로 표시)
    path.add(new PathFrame(page, -1));
}

/**
 * COW 전파 (Split 없이)
 */
private long propagateCow(List<PathFrame> path, int fromIndex, Page modifiedPage) {
    long childPageId = writePage(modifiedPage);
    
    // 경로를 거슬러 올라가며 부모 갱신
    for (int i = fromIndex - 1; i >= 0; i--) {
        PathFrame frame = path.get(i);
        Page newParent = copyPage(frame.page);
        newParent.setChild(frame.childIndex, childPageId);
        childPageId = writePage(newParent);
    }
    
    return childPageId;  // 새 루트
}
```

### 4.4 Split 알고리즘 상세

```java
/**
 * Split을 동반한 삽입
 */
private long insertWithSplit(List<PathFrame> path, int insertPos, 
                              byte[] key, long valueRef) {
    // 1. 리프 분할
    PathFrame leafFrame = path.get(path.size() - 1);
    Page leaf = leafFrame.page;
    
    LeafSplitResult splitResult = splitLeaf(leaf, insertPos, key, valueRef);
    
    // 2. 분할된 페이지들 저장
    long leftPageId = writePage(splitResult.left);
    long rightPageId = writePage(splitResult.right);
    
    // 3. Separator key를 부모에 삽입 (재귀적으로)
    return insertIntoParent(path, path.size() - 2, 
                            leftPageId, splitResult.separatorKey, rightPageId);
}

/**
 * 리프 분할
 */
private LeafSplitResult splitLeaf(Page leaf, int insertPos, 
                                   byte[] newKey, long newValueRef) {
    // 모든 엔트리 수집 (새 엔트리 포함)
    List<LeafEntry> allEntries = new ArrayList<>();
    
    int count = leaf.getEntryCount();
    for (int i = 0; i < count; i++) {
        if (i == insertPos) {
            allEntries.add(new LeafEntry(newKey, newValueRef));
        }
        allEntries.add(new LeafEntry(leaf.getKey(i), leaf.getValueRef(i)));
    }
    if (insertPos == count) {
        allEntries.add(new LeafEntry(newKey, newValueRef));
    }
    
    // 분할 지점
    int splitPoint = allEntries.size() / 2;
    
    // 왼쪽 리프 생성
    Page leftLeaf = createEmptyLeaf();
    for (int i = 0; i < splitPoint; i++) {
        LeafEntry e = allEntries.get(i);
        leftLeaf.insertEntry(i, encodeLeafEntry(e.key, e.valueRef));
    }
    
    // 오른쪽 리프 생성
    Page rightLeaf = createEmptyLeaf();
    for (int i = splitPoint; i < allEntries.size(); i++) {
        LeafEntry e = allEntries.get(i);
        rightLeaf.insertEntry(i - splitPoint, encodeLeafEntry(e.key, e.valueRef));
    }
    
    // nextLeaf 연결
    leftLeaf.setNextLeafPageId(/* rightLeaf의 pageId - 아직 모름, 나중에 설정 */);
    
    // Separator key = 오른쪽 첫 번째 키
    byte[] separatorKey = allEntries.get(splitPoint).key;
    
    return new LeafSplitResult(leftLeaf, rightLeaf, separatorKey);
}

/**
 * 부모에 separator 삽입 (재귀적)
 */
private long insertIntoParent(List<PathFrame> path, int parentIndex,
                               long leftChildId, byte[] separatorKey, 
                               long rightChildId) {
    if (parentIndex < 0) {
        // 루트까지 도달: 새 루트 생성
        return createNewRoot(leftChildId, separatorKey, rightChildId);
    }
    
    PathFrame parentFrame = path.get(parentIndex);
    Page parent = parentFrame.page;
    int insertKeyPos = parentFrame.childIndex;
    
    // 부모에 공간 있는지 확인
    byte[] keyBlob = encodeInternalKey(separatorKey);
    
    if (parent.hasSpaceForKey(keyBlob)) {
        // 공간 있음: 삽입
        Page newParent = copyPage(parent);
        
        // children 배열에서 기존 child를 left로 유지, right를 삽입
        newParent.setChild(insertKeyPos, leftChildId);
        newParent.insertChild(insertKeyPos + 1, rightChildId);
        newParent.insertKey(insertKeyPos, keyBlob);
        
        return propagateCow(path, parentIndex, newParent);
    } else {
        // 부모도 분할 필요
        return splitInternal(path, parentIndex, 
                             leftChildId, separatorKey, rightChildId);
    }
}

/**
 * Internal 노드 분할
 */
private long splitInternal(List<PathFrame> path, int nodeIndex,
                            long newLeftChild, byte[] newKey, 
                            long newRightChild) {
    PathFrame frame = path.get(nodeIndex);
    Page node = frame.page;
    
    // 모든 키/자식 수집 (새 키/자식 포함)
    List<byte[]> allKeys = new ArrayList<>();
    List<Long> allChildren = new ArrayList<>();
    
    int keyCount = node.getKeyCount();
    int insertPos = frame.childIndex;
    
    for (int i = 0; i <= keyCount; i++) {
        if (i == insertPos) {
            allChildren.add(newLeftChild);
        } else if (i == insertPos + 1) {
            allChildren.add(newRightChild);
        } else {
            allChildren.add(node.getChild(i < insertPos + 1 ? i : i - 1));
        }
        
        if (i < keyCount) {
            if (i == insertPos) {
                allKeys.add(newKey);
            }
            allKeys.add(node.getKey(i < insertPos ? i : i));
        } else if (i == insertPos) {
            allKeys.add(newKey);
        }
    }
    
    // 분할 지점 (중간 키는 부모로 promote)
    int splitKeyIndex = allKeys.size() / 2;
    byte[] promoteKey = allKeys.get(splitKeyIndex);
    
    // 왼쪽 Internal 생성
    Page leftInternal = createEmptyInternal(node.getLevel());
    for (int i = 0; i < splitKeyIndex; i++) {
        leftInternal.insertChild(i, allChildren.get(i));
        leftInternal.insertKey(i, allKeys.get(i));
    }
    leftInternal.insertChild(splitKeyIndex, allChildren.get(splitKeyIndex));
    
    // 오른쪽 Internal 생성
    Page rightInternal = createEmptyInternal(node.getLevel());
    int rightStart = splitKeyIndex + 1;
    for (int i = rightStart; i < allKeys.size(); i++) {
        rightInternal.insertChild(i - rightStart, allChildren.get(i));
        rightInternal.insertKey(i - rightStart, allKeys.get(i));
    }
    rightInternal.insertChild(allKeys.size() - rightStart, 
                               allChildren.get(allChildren.size() - 1));
    
    // 페이지 저장
    long leftPageId = writePage(leftInternal);
    long rightPageId = writePage(rightInternal);
    
    // 재귀적으로 부모에 삽입
    return insertIntoParent(path, nodeIndex - 1, 
                            leftPageId, promoteKey, rightPageId);
}

/**
 * 새 루트 생성 (트리 높이 증가)
 */
private long createNewRoot(long leftChild, byte[] separatorKey, long rightChild) {
    Page root = createEmptyInternal(/* level = 기존 루트 + 1 */);
    root.insertChild(0, leftChild);
    root.insertKey(0, encodeInternalKey(separatorKey));
    root.insertChild(1, rightChild);
    return writePage(root);
}
```

### 4.5 B+Tree Delete 알고리즘

```java
/**
 * B+Tree 삭제 (COW, merge 없는 단순 버전)
 * 
 * 설계 결정: 초기 버전에서는 merge를 구현하지 않음
 * - COW + append-only에서는 공간 재활용이 어려움
 * - merge 구현 복잡도가 높고 버그 위험
 * - 컴팩션으로 공간 회수
 * 
 * @return 새 루트 pageId (삭제 후 빈 트리면 0)
 */
public long delete(long rootPageId, byte[] key) {
    if (rootPageId == 0) return 0;
    
    // 1. 검색 경로 수집
    List<PathFrame> path = new ArrayList<>();
    collectPath(rootPageId, key, path);
    
    // 2. 리프에서 키 찾기
    PathFrame leafFrame = path.get(path.size() - 1);
    Page leaf = leafFrame.page;
    
    int deletePos = binarySearchLeaf(leaf, key);
    if (deletePos < 0) {
        // 키가 없음: 변경 없음
        return rootPageId;
    }
    
    // 3. 리프에서 엔트리 제거
    Page newLeaf = copyPage(leaf);
    newLeaf.deleteEntry(deletePos);
    
    // 4. 리프가 비어있으면?
    if (newLeaf.getEntryCount() == 0) {
        // 단순 정책: 빈 리프도 유지 (merge 없음)
        // 또는: 리프가 하나뿐이면 루트가 비어있는 것
        if (path.size() == 1) {
            // 루트 리프가 비어있음
            return 0;  // 빈 트리
        }
    }
    
    // 5. COW 전파
    return propagateCow(path, path.size() - 1, newLeaf);
}
```

### 4.6 B+Tree Cursor (순회)

```java
/**
 * 리프 순회를 위한 Cursor
 */
public class BTreeCursor implements Iterator<LeafEntry> {
    private final BPlusTree tree;
    private Page currentLeaf;
    private int currentIndex;
    private byte[] endKey;  // null이면 끝까지
    private boolean inclusive;
    
    public BTreeCursor(BPlusTree tree, byte[] startKey, byte[] endKey, 
                       boolean startInclusive, boolean endInclusive) {
        this.tree = tree;
        this.endKey = endKey;
        this.inclusive = endInclusive;
        
        // startKey로 시작 위치 찾기
        if (startKey == null) {
            // 첫 번째 리프의 첫 엔트리
            currentLeaf = tree.findFirstLeaf();
            currentIndex = 0;
        } else {
            currentLeaf = tree.findLeafContaining(startKey);
            currentIndex = tree.findInsertPosition(currentLeaf, startKey);
            
            if (!startInclusive && currentIndex < currentLeaf.getEntryCount()) {
                byte[] foundKey = currentLeaf.getKey(currentIndex);
                if (tree.comparator.compare(startKey, foundKey) == 0) {
                    currentIndex++;  // startKey 제외
                }
            }
        }
        
        advanceIfNeeded();
    }
    
    @Override
    public boolean hasNext() {
        return currentLeaf != null && currentIndex < currentLeaf.getEntryCount();
    }
    
    @Override
    public LeafEntry next() {
        if (!hasNext()) throw new NoSuchElementException();
        
        LeafEntry entry = new LeafEntry(
            currentLeaf.getKey(currentIndex),
            currentLeaf.getValueRef(currentIndex)
        );
        
        currentIndex++;
        advanceIfNeeded();
        
        return entry;
    }
    
    private void advanceIfNeeded() {
        // 현재 리프 끝에 도달했으면 다음 리프로
        while (currentLeaf != null && 
               currentIndex >= currentLeaf.getEntryCount()) {
            long nextPageId = currentLeaf.getNextLeafPageId();
            if (nextPageId == 0) {
                currentLeaf = null;  // 순회 종료
            } else {
                currentLeaf = tree.readPage(nextPageId);
                currentIndex = 0;
            }
        }
        
        // endKey 체크
        if (currentLeaf != null && endKey != null && 
            currentIndex < currentLeaf.getEntryCount()) {
            byte[] currentKey = currentLeaf.getKey(currentIndex);
            int cmp = tree.comparator.compare(currentKey, endKey);
            if (cmp > 0 || (cmp == 0 && !inclusive)) {
                currentLeaf = null;  // 순회 종료
            }
        }
    }
}
```

---

## 5. Order-Statistic Tree 구현 상세

### 5.1 OST 개요

List<E>의 `get(i)`, `add(i, elem)`, `remove(i)` 연산을 O(log N)에 수행하기 위한 자료구조입니다.

```
일반 B+Tree (index-keyed):
  add(5, "X") → 인덱스 5 이후 모든 키가 +1씩 변경 → O(N)

OST:
  각 Internal 노드가 자식 서브트리의 원소 수를 저장
  인덱스 기반 탐색을 O(log N)에 수행
  삽입/삭제 시 경로상 count만 갱신
```

### 5.2 OST 페이지 레이아웃

**OST_INTERNAL Payload:**
```
Offset  Size        Field               Description
────────────────────────────────────────────────────────────────────
0x00    2           level               Tree level
0x02    2           childCount          Number of children
0x04    4           reserved            Alignment
0x08    8*C         children[C]         Child page IDs
var     8*C         subtreeCounts[C]    Elements in each subtree
────────────────────────────────────────────────────────────────────
```

**OST_LEAF Payload:**
```
Offset  Size        Field               Description
────────────────────────────────────────────────────────────────────
0x00    2           elemCount           Number of elements
0x02    2           reserved
0x04    8           nextLeafPageId      For iteration
0x0C    8*N         elemRefs[N]         valueRef for each element
────────────────────────────────────────────────────────────────────
```

### 5.3 OST Get 알고리즘

```java
/**
 * 인덱스로 원소 조회
 * @throws IndexOutOfBoundsException
 */
public long ostGet(long rootPageId, int index) {
    if (rootPageId == 0 || index < 0) {
        throw new IndexOutOfBoundsException("Index: " + index);
    }
    
    Page node = readPage(rootPageId);
    int remaining = index;
    
    while (node.getType() == OST_INTERNAL) {
        int childCount = node.getChildCount();
        int targetChild = -1;
        
        for (int i = 0; i < childCount; i++) {
            long count = node.getSubtreeCount(i);
            if (remaining < count) {
                targetChild = i;
                break;
            }
            remaining -= count;
        }
        
        if (targetChild < 0) {
            throw new IndexOutOfBoundsException("Index: " + index);
        }
        
        node = readPage(node.getChild(targetChild));
    }
    
    // Leaf에 도달
    if (remaining >= node.getElemCount()) {
        throw new IndexOutOfBoundsException("Index: " + index);
    }
    
    return node.getElemRef(remaining);
}
```

### 5.4 OST Insert 알고리즘

```java
/**
 * 인덱스 위치에 원소 삽입
 */
public long ostInsert(long rootPageId, int index, long valueRef) {
    if (rootPageId == 0) {
        if (index != 0) {
            throw new IndexOutOfBoundsException("Index: " + index);
        }
        return createSingleElementLeaf(valueRef);
    }
    
    // 1. 검색 경로 수집
    List<OstPathFrame> path = new ArrayList<>();
    int remaining = index;
    
    Page node = readPage(rootPageId);
    
    while (node.getType() == OST_INTERNAL) {
        int childCount = node.getChildCount();
        int targetChild = childCount - 1;  // 기본: 마지막 자식
        
        for (int i = 0; i < childCount; i++) {
            long count = node.getSubtreeCount(i);
            if (remaining <= count) {  // <= 로 경계 포함
                targetChild = i;
                break;
            }
            remaining -= count;
        }
        
        path.add(new OstPathFrame(node, targetChild, remaining));
        node = readPage(node.getChild(targetChild));
    }
    
    // 2. 리프에 삽입
    int localIndex = remaining;
    Page newLeaf = copyPage(node);
    
    if (localIndex > newLeaf.getElemCount()) {
        throw new IndexOutOfBoundsException("Index: " + index);
    }
    
    if (newLeaf.getElemCount() < OST_MAX_LEAF_ELEMS) {
        // 공간 있음: 단순 삽입
        newLeaf.insertElemAt(localIndex, valueRef);
        return propagateOstCow(path, newLeaf, +1);
    } else {
        // 분할 필요
        return ostInsertWithSplit(path, localIndex, valueRef);
    }
}

/**
 * OST COW 전파 (count 갱신 포함)
 */
private long propagateOstCow(List<OstPathFrame> path, Page leaf, int countDelta) {
    long childPageId = writePage(leaf);
    
    for (int i = path.size() - 1; i >= 0; i--) {
        OstPathFrame frame = path.get(i);
        Page newParent = copyPage(frame.page);
        
        newParent.setChild(frame.childIndex, childPageId);
        
        // 핵심: subtreeCount 갱신
        long oldCount = newParent.getSubtreeCount(frame.childIndex);
        newParent.setSubtreeCount(frame.childIndex, oldCount + countDelta);
        
        childPageId = writePage(newParent);
    }
    
    return childPageId;
}
```

### 5.5 OST Leaf Split

```java
/**
 * OST 리프 분할
 */
private long ostInsertWithSplit(List<OstPathFrame> path, 
                                 int localIndex, long valueRef) {
    Page leaf = path.isEmpty() ? readPage(rootPageId) 
                               : readPage(path.get(path.size()-1).childPageId);
    
    // 모든 원소 수집 (새 원소 포함)
    List<Long> allRefs = new ArrayList<>();
    for (int i = 0; i < leaf.getElemCount(); i++) {
        if (i == localIndex) {
            allRefs.add(valueRef);
        }
        allRefs.add(leaf.getElemRef(i));
    }
    if (localIndex == leaf.getElemCount()) {
        allRefs.add(valueRef);
    }
    
    // 분할
    int splitPoint = allRefs.size() / 2;
    
    Page leftLeaf = createEmptyOstLeaf();
    for (int i = 0; i < splitPoint; i++) {
        leftLeaf.insertElemAt(i, allRefs.get(i));
    }
    
    Page rightLeaf = createEmptyOstLeaf();
    for (int i = splitPoint; i < allRefs.size(); i++) {
        rightLeaf.insertElemAt(i - splitPoint, allRefs.get(i));
    }
    
    // nextLeaf 연결
    leftLeaf.setNextLeafPageId(/* right's id */);
    rightLeaf.setNextLeafPageId(leaf.getNextLeafPageId());
    
    long leftPageId = writePage(leftLeaf);
    long rightPageId = writePage(rightLeaf);
    
    // 부모에 삽입
    return ostInsertIntoParent(path, leftPageId, splitPoint, 
                               rightPageId, allRefs.size() - splitPoint);
}

/**
 * OST 부모에 자식 삽입
 */
private long ostInsertIntoParent(List<OstPathFrame> path, 
                                  long leftChildId, long leftCount,
                                  long rightChildId, long rightCount) {
    if (path.isEmpty()) {
        // 새 루트 생성
        Page root = createEmptyOstInternal(1);
        root.insertChild(0, leftChildId);
        root.setSubtreeCount(0, leftCount);
        root.insertChild(1, rightChildId);
        root.setSubtreeCount(1, rightCount);
        return writePage(root);
    }
    
    OstPathFrame parentFrame = path.get(path.size() - 1);
    Page parent = parentFrame.page;
    int insertPos = parentFrame.childIndex;
    
    // 부모 수정
    Page newParent = copyPage(parent);
    
    // 기존 자식을 left로 대체
    newParent.setChild(insertPos, leftChildId);
    newParent.setSubtreeCount(insertPos, leftCount);
    
    // right를 그 다음에 삽입
    newParent.insertChild(insertPos + 1, rightChildId);
    newParent.setSubtreeCount(insertPos + 1, rightCount);
    
    // 부모에 공간 있는지 확인
    if (newParent.getChildCount() <= OST_MAX_INTERNAL_CHILDREN) {
        // 공간 있음
        path.remove(path.size() - 1);
        // totalCount는 기존과 동일 (원소가 재분배된 것뿐)
        return propagateOstCow(path, newParent, 0);
    } else {
        // 부모도 분할 (재귀)
        return ostSplitInternal(path, newParent);
    }
}
```

### 5.6 OST Count 검증

```java
/**
 * OST 무결성 검증 - count 합 일치 확인
 */
public boolean verifyOstCounts(long rootPageId) {
    if (rootPageId == 0) return true;
    
    return verifyOstCountsRecursive(rootPageId) >= 0;
}

private long verifyOstCountsRecursive(long pageId) {
    Page page = readPage(pageId);
    
    if (page.getType() == OST_LEAF) {
        return page.getElemCount();
    }
    
    // Internal 노드
    long totalCount = 0;
    for (int i = 0; i < page.getChildCount(); i++) {
        long childPageId = page.getChild(i);
        long actualCount = verifyOstCountsRecursive(childPageId);
        
        if (actualCount < 0) return -1;  // 자식에서 오류
        
        long storedCount = page.getSubtreeCount(i);
        if (actualCount != storedCount) {
            // Count 불일치!
            log.error("OST count mismatch at page {}, child {}: " +
                      "stored={}, actual={}", 
                      pageId, i, storedCount, actualCount);
            return -1;
        }
        
        totalCount += actualCount;
    }
    
    return totalCount;
}
```

---

## 6. Deque 시퀀스 관리

### 6.1 시퀀스 설계

```
Deque는 B+Tree를 사용하되, 키가 시퀀스 번호(i64)입니다.

초기 상태:
  headSeq = 0
  tailSeq = -1
  size = 0
  
  headSeq > tailSeq는 빈 Deque를 의미
  size = tailSeq - headSeq + 1 (비어있지 않을 때)

addFirst("A"):
  headSeq = 0 - 1 = -1
  insert(key=-1, value="A")
  size = 1
  
  Tree: {-1 → "A"}
  headSeq=-1, tailSeq=-1

addLast("B"):
  tailSeq = -1 + 1 = 0
  insert(key=0, value="B")
  size = 2
  
  Tree: {-1 → "A", 0 → "B"}
  headSeq=-1, tailSeq=0

addFirst("C"):
  headSeq = -1 - 1 = -2
  insert(key=-2, value="C")
  size = 3
  
  Tree: {-2 → "C", -1 → "A", 0 → "B"}
  headSeq=-2, tailSeq=0

removeFirst():
  find(key=-2) → "C"
  delete(key=-2)
  headSeq = -2 + 1 = -1
  size = 2
  return "C"
  
  Tree: {-1 → "A", 0 → "B"}
  headSeq=-1, tailSeq=0
```

### 6.2 시퀀스 인코딩

```java
/**
 * i64를 정렬 가능한 8바이트로 인코딩
 * 
 * 문제: Little-endian으로 저장하면 unsigned lexicographic 비교가 
 *       signed 순서와 일치하지 않음
 * 
 * 해결: Sign bit를 반전하여 저장
 *       음수 → 양수보다 작게
 *       같은 부호 내에서는 절대값 순서 유지
 */
public static byte[] encodeI64Sortable(long value) {
    // Sign bit 반전: MIN_VALUE → 0, 0 → 0x8000..., MAX_VALUE → 0xFFFF...
    long encoded = value ^ 0x8000_0000_0000_0000L;
    
    byte[] buf = new byte[8];
    // Big-endian으로 저장해야 lexicographic = numeric
    for (int i = 0; i < 8; i++) {
        buf[i] = (byte)(encoded >>> (56 - i * 8));
    }
    return buf;
}

public static long decodeI64Sortable(byte[] buf) {
    long encoded = 0;
    for (int i = 0; i < 8; i++) {
        encoded = (encoded << 8) | (buf[i] & 0xFF);
    }
    return encoded ^ 0x8000_0000_0000_0000L;
}
```

### 6.3 Deque 연산 구현

```java
public class FxDeque<E> implements Deque<E> {
    private final FxStore store;
    private final long collectionId;
    private final FxCodec<E> codec;
    private final BPlusTree btree;
    
    // Cached state (항상 최신 State와 동기화)
    private long headSeq;
    private long tailSeq;
    private long size;
    
    @Override
    public void addFirst(E elem) {
        if (elem == null) throw new NullPointerException();
        
        // 1. 값 레코드 작성
        byte[] payload = codec.encode(elem);
        long valueRef = store.writeValueRecord(payload);
        
        // 2. 새 headSeq 계산
        long newHeadSeq = (size == 0) ? 0 : headSeq - 1;
        byte[] key = encodeI64Sortable(newHeadSeq);
        
        // 3. B+Tree 삽입
        long newRoot = btree.insert(getRoot(), key, valueRef);
        
        // 4. State 갱신
        headSeq = newHeadSeq;
        if (size == 0) {
            tailSeq = newHeadSeq;
        }
        size++;
        
        updateState(newRoot, size, headSeq, tailSeq);
    }
    
    @Override
    public void addLast(E elem) {
        if (elem == null) throw new NullPointerException();
        
        byte[] payload = codec.encode(elem);
        long valueRef = store.writeValueRecord(payload);
        
        long newTailSeq = (size == 0) ? 0 : tailSeq + 1;
        byte[] key = encodeI64Sortable(newTailSeq);
        
        long newRoot = btree.insert(getRoot(), key, valueRef);
        
        tailSeq = newTailSeq;
        if (size == 0) {
            headSeq = newTailSeq;
        }
        size++;
        
        updateState(newRoot, size, headSeq, tailSeq);
    }
    
    @Override
    public E removeFirst() {
        if (size == 0) throw new NoSuchElementException();
        
        byte[] key = encodeI64Sortable(headSeq);
        
        // 1. 값 조회
        Long valueRef = btree.find(getRoot(), key);
        if (valueRef == null) {
            throw new IllegalStateException("Deque corrupted: head entry not found");
        }
        
        E elem = codec.decode(store.readValueRecord(valueRef));
        
        // 2. 삭제
        long newRoot = btree.delete(getRoot(), key);
        
        // 3. State 갱신
        headSeq++;
        size--;
        
        if (size == 0) {
            // Reset to initial state
            headSeq = 0;
            tailSeq = -1;
        }
        
        updateState(newRoot, size, headSeq, tailSeq);
        return elem;
    }
    
    @Override
    public E removeLast() {
        if (size == 0) throw new NoSuchElementException();
        
        byte[] key = encodeI64Sortable(tailSeq);
        
        Long valueRef = btree.find(getRoot(), key);
        if (valueRef == null) {
            throw new IllegalStateException("Deque corrupted: tail entry not found");
        }
        
        E elem = codec.decode(store.readValueRecord(valueRef));
        
        long newRoot = btree.delete(getRoot(), key);
        
        tailSeq--;
        size--;
        
        if (size == 0) {
            headSeq = 0;
            tailSeq = -1;
        }
        
        updateState(newRoot, size, headSeq, tailSeq);
        return elem;
    }
    
    @Override
    public E peekFirst() {
        if (size == 0) return null;
        
        byte[] key = encodeI64Sortable(headSeq);
        Long valueRef = btree.find(getRoot(), key);
        return valueRef != null 
            ? codec.decode(store.readValueRecord(valueRef)) 
            : null;
    }
    
    @Override
    public E peekLast() {
        if (size == 0) return null;
        
        byte[] key = encodeI64Sortable(tailSeq);
        Long valueRef = btree.find(getRoot(), key);
        return valueRef != null 
            ? codec.decode(store.readValueRecord(valueRef)) 
            : null;
    }
    
    @Override
    public Iterator<E> iterator() {
        // head → tail 순서로 순회
        return new DequeIterator(headSeq, tailSeq, false);
    }
    
    @Override
    public Iterator<E> descendingIterator() {
        // tail → head 순서로 순회
        return new DequeIterator(headSeq, tailSeq, true);
    }
}
```

---

## 7. Catalog/State 분리 아키텍처

### 7.1 왜 분리가 필수인가 - 정량적 분석

```
시나리오: 10,000개의 Map 컬렉션, 각 Map에 100회 put 수행

분리하지 않은 경우 (단일 Catalog):
  - 컬렉션당 CatalogEntry 크기: ~100 bytes (name 20B + meta 80B)
  - Catalog 총 크기: 10,000 × 100B = 1MB
  - 매 put마다 Catalog COW 발생
  - 총 put 횟수: 10,000 × 100 = 1,000,000
  - 각 COW에서 path 상 페이지 복제: ~log(10000) ≈ 4 페이지
  - COW 비용: 1,000,000 × 4 × 4KB = 16GB 쓰기!

분리한 경우:
  - Catalog: create 시 1회만 갱신 (10,000회)
  - State entry 크기: 48 bytes (고정)
  - State 총 크기: 10,000 × 48B = 480KB
  - State COW는 매 put마다 발생하지만 트리가 작고 키가 고정 크기
  - COW 비용: 1,000,000 × 3 × 4KB ≈ 12GB
  - 그러나 State 트리는 훨씬 효율적으로 캐시됨

결론: 분리로 인해 "빈번한 연산"의 COW 비용이 크게 감소
```

### 7.2 CatalogTree 구현

```java
/**
 * Catalog B+Tree
 * Key: name (UTF-8 bytes)
 * Value: CatalogEntry (inline in leaf)
 */
public class CatalogTree {
    private final BPlusTree btree;
    
    // Comparator: unsigned lexicographic for UTF-8
    private static final Comparator<byte[]> NAME_COMPARATOR = (a, b) -> {
        int len = Math.min(a.length, b.length);
        for (int i = 0; i < len; i++) {
            int ua = a[i] & 0xFF;
            int ub = b[i] & 0xFF;
            if (ua != ub) return ua - ub;
        }
        return Integer.compare(a.length, b.length);
    };
    
    /**
     * CatalogEntry 조회
     */
    public CatalogEntry find(String name) {
        byte[] key = name.getBytes(StandardCharsets.UTF_8);
        Long valueRef = btree.find(root, key);
        
        if (valueRef == null) return null;
        
        byte[] data = storage.readValueRecord(valueRef);
        return CatalogEntry.decode(data);
    }
    
    /**
     * CatalogEntry 삽입
     * @return 새 루트 pageId
     */
    public long insert(String name, CatalogEntry entry) {
        byte[] key = name.getBytes(StandardCharsets.UTF_8);
        byte[] value = entry.encode();
        long valueRef = storage.writeValueRecord(value);
        
        return btree.insert(root, key, valueRef);
    }
    
    /**
     * CatalogEntry 삭제
     */
    public long delete(String name) {
        byte[] key = name.getBytes(StandardCharsets.UTF_8);
        return btree.delete(root, key);
    }
    
    /**
     * 전체 순회 (list용)
     */
    public List<CatalogEntry> scanAll() {
        List<CatalogEntry> result = new ArrayList<>();
        
        BTreeCursor cursor = btree.cursor(null, null);
        while (cursor.hasNext()) {
            LeafEntry entry = cursor.next();
            byte[] data = storage.readValueRecord(entry.valueRef);
            CatalogEntry ce = CatalogEntry.decode(data);
            ce.name = new String(entry.key, StandardCharsets.UTF_8);
            result.add(ce);
        }
        
        return result;
    }
}
```

### 7.3 StateTree 구현

```java
/**
 * State B+Tree
 * Key: collectionId (8 bytes, big-endian for sorting)
 * Value: CollectionState (fixed 48 bytes, inline)
 */
public class StateTree {
    private final BPlusTree btree;
    
    // Comparator: unsigned 64-bit comparison
    private static final Comparator<byte[]> ID_COMPARATOR = (a, b) -> {
        // Both are exactly 8 bytes
        for (int i = 0; i < 8; i++) {
            int ua = a[i] & 0xFF;
            int ub = b[i] & 0xFF;
            if (ua != ub) return ua - ub;
        }
        return 0;
    };
    
    private byte[] encodeId(long collectionId) {
        byte[] buf = new byte[8];
        for (int i = 0; i < 8; i++) {
            buf[i] = (byte)(collectionId >>> (56 - i * 8));
        }
        return buf;
    }
    
    /**
     * CollectionState 조회
     */
    public CollectionState find(long collectionId) {
        byte[] key = encodeId(collectionId);
        Long valueRef = btree.find(root, key);
        
        if (valueRef == null) return null;
        
        byte[] data = storage.readValueRecord(valueRef);
        return CollectionState.decode(data);
    }
    
    /**
     * CollectionState 갱신 (upsert)
     * @return 새 루트 pageId
     */
    public long upsert(long collectionId, CollectionState state) {
        byte[] key = encodeId(collectionId);
        byte[] value = state.encode();
        long valueRef = storage.writeValueRecord(value);
        
        return btree.insert(root, key, valueRef);  // insert handles replace
    }
    
    /**
     * CollectionState 삭제
     */
    public long delete(long collectionId) {
        byte[] key = encodeId(collectionId);
        return btree.delete(root, key);
    }
}
```

### 7.4 상태 동기화 흐름

```
Map.put(key, value) 호출 시:

1. [Catalog 조회] (캐시에서)
   name → CatalogEntry { collectionId, kind, codecs }
   
2. [State 조회] (캐시에서 또는 트리에서)
   collectionId → CollectionState { rootPageId, size }
   
3. [값 레코드 작성]
   valueRef = writeValueRecord(encode(value))
   
4. [컬렉션 인덱스 COW]
   newCollectionRoot = btree.insert(state.rootPageId, encodeKey, valueRef)
   
5. [State 갱신]
   newState = { rootPageId: newCollectionRoot, size: size+1 }
   newStateRoot = stateTree.upsert(collectionId, newState)
   
6. [커밋]
   AUTO: 즉시 헤더 교체
   BATCH: pendingStateRoot = newStateRoot

전체 과정에서 Catalog는 전혀 수정되지 않음!
```

---

## 8. 커밋 프로토콜과 크래시 복구

### 8.1 SYNC 커밋 순서

```java
/**
 * SYNC 모드 커밋 순서 (크래시 안전성 보장)
 */
public void commitSync() {
    // 1. 모든 신규 페이지/레코드가 파일에 기록됨을 보장
    //    (write 호출은 이미 완료되어 있음)
    
    // 2. 데이터 동기화
    storage.force(false);  // fsync data only
    
    // 3. 새 헤더 작성
    int targetSlot = (currentSlot == 'A') ? 'B' : 'A';
    long targetOffset = (targetSlot == 'A') ? HEADER_A_OFFSET : HEADER_B_OFFSET;
    
    CommitHeader newHeader = new CommitHeader();
    newHeader.seqNo = committedHeader.seqNo + 1;
    newHeader.allocTail = allocator.getTail();
    newHeader.catalogRootPageId = effectiveCatalogRoot();
    newHeader.stateRootPageId = effectiveStateRoot();
    newHeader.nextCollectionId = this.nextCollectionId;
    newHeader.commitEpochMs = System.currentTimeMillis();
    
    byte[] headerBytes = newHeader.encode();
    storage.write(targetOffset, headerBytes, 0, headerBytes.length);
    
    // 4. 헤더 동기화 (메타데이터 포함)
    storage.force(true);  // fsync data + metadata
    
    // 5. 상태 갱신
    committedHeader = newHeader;
    currentSlot = targetSlot;
    clearPendingState();
}
```

**왜 이 순서가 중요한가:**
```
올바른 순서:
  [Data Pages] → force(data) → [Header] → force(meta)
  
  크래시 시나리오 1: Data force 전 크래시
    → 헤더가 갱신되지 않음 → 이전 커밋 상태로 복구
    
  크래시 시나리오 2: Data force 후, Header 작성 전 크래시
    → 헤더가 갱신되지 않음 → 이전 커밋 상태로 복구
    → 신규 데이터는 orphan으로 남음 (컴팩션에서 제거)
    
  크래시 시나리오 3: Header 작성 후, force 전 크래시
    → 헤더가 디스크에 도달했을 수도, 안 했을 수도 있음
    → CRC 검증으로 판별
    → 도달했으면 새 상태, 안 했으면 이전 상태

잘못된 순서:
  [Header] → [Data Pages]
  
  크래시 시 헤더가 가리키는 페이지가 디스크에 없을 수 있음!
```

### 8.2 ASYNC 커밋

```java
/**
 * ASYNC 모드 커밋 (빠르지만 크래시 시 손실 가능)
 */
public void commitAsync() {
    // force 호출 없이 헤더만 작성
    int targetSlot = (currentSlot == 'A') ? 'B' : 'A';
    long targetOffset = (targetSlot == 'A') ? HEADER_A_OFFSET : HEADER_B_OFFSET;
    
    CommitHeader newHeader = buildNewHeader();
    byte[] headerBytes = newHeader.encode();
    storage.write(targetOffset, headerBytes, 0, headerBytes.length);
    
    // OS 버퍼에만 기록됨, 실제 디스크 동기화는 OS에 위임
    
    committedHeader = newHeader;
    currentSlot = targetSlot;
    clearPendingState();
}
```

### 8.3 BATCH 모드 상태 관리

```java
/**
 * BATCH 모드 상태
 */
public class BatchState {
    // 커밋된 상태 (파일에서 읽은 최신)
    CommitHeader committedHeader;
    char currentSlot;  // 'A' or 'B'
    
    // Pending 상태 (BATCH에서만 사용)
    Long pendingCatalogRoot = null;
    Long pendingStateRoot = null;
    Long pendingAllocTail = null;
    long pendingNextCollectionId;
    
    // 유효한 루트 반환
    long effectiveCatalogRoot() {
        return pendingCatalogRoot != null 
            ? pendingCatalogRoot 
            : committedHeader.catalogRootPageId;
    }
    
    long effectiveStateRoot() {
        return pendingStateRoot != null 
            ? pendingStateRoot 
            : committedHeader.stateRootPageId;
    }
    
    // 변경 기록
    void recordCatalogChange(long newRoot) {
        pendingCatalogRoot = newRoot;
    }
    
    void recordStateChange(long newRoot) {
        pendingStateRoot = newRoot;
    }
    
    // 커밋
    void commit(Durability durability) {
        if (!hasPendingChanges()) return;
        
        CommitHeader newHeader = new CommitHeader();
        newHeader.seqNo = committedHeader.seqNo + 1;
        newHeader.allocTail = pendingAllocTail != null 
            ? pendingAllocTail 
            : allocator.getTail();
        newHeader.catalogRootPageId = effectiveCatalogRoot();
        newHeader.stateRootPageId = effectiveStateRoot();
        newHeader.nextCollectionId = pendingNextCollectionId;
        newHeader.commitEpochMs = System.currentTimeMillis();
        
        // 헤더 작성
        writeHeader(newHeader);
        
        if (durability == Durability.SYNC) {
            storage.force(true);
        }
        
        // 상태 갱신
        committedHeader = newHeader;
        currentSlot = oppositeSlot(currentSlot);
        clearPending();
    }
    
    // 롤백
    void rollback() {
        // Pending 포인터만 폐기
        // 이미 기록된 페이지/레코드는 dead로 남음
        clearPending();
    }
    
    private void clearPending() {
        pendingCatalogRoot = null;
        pendingStateRoot = null;
        pendingAllocTail = null;
        pendingNextCollectionId = committedHeader.nextCollectionId;
    }
    
    boolean hasPendingChanges() {
        return pendingCatalogRoot != null || pendingStateRoot != null;
    }
}
```

### 8.4 크래시 복구 흐름

```java
/**
 * 파일 열기 시 크래시 복구
 */
public CommitHeader recover(Storage storage) {
    // 1. Superblock 검증
    byte[] superblock = new byte[SUPERBLOCK_SIZE];
    storage.read(0, superblock, 0, SUPERBLOCK_SIZE);
    
    if (!verifySuperblock(superblock)) {
        throw new FxException("Superblock corrupted", CORRUPTION);
    }
    
    // 2. 두 헤더 슬롯 읽기
    byte[] slotA = new byte[HEADER_SIZE];
    byte[] slotB = new byte[HEADER_SIZE];
    storage.read(HEADER_A_OFFSET, slotA, 0, HEADER_SIZE);
    storage.read(HEADER_B_OFFSET, slotB, 0, HEADER_SIZE);
    
    // 3. CRC 검증
    boolean aValid = verifyHeaderCrc(slotA);
    boolean bValid = verifyHeaderCrc(slotB);
    
    if (!aValid && !bValid) {
        throw new FxException("Both headers corrupted", CORRUPTION);
    }
    
    // 4. 유효한 슬롯 중 seqNo가 큰 것 선택
    CommitHeader header;
    char selectedSlot;
    
    if (!aValid) {
        header = parseHeader(slotB);
        selectedSlot = 'B';
    } else if (!bValid) {
        header = parseHeader(slotA);
        selectedSlot = 'A';
    } else {
        CommitHeader headerA = parseHeader(slotA);
        CommitHeader headerB = parseHeader(slotB);
        
        if (headerA.seqNo >= headerB.seqNo) {
            header = headerA;
            selectedSlot = 'A';
        } else {
            header = headerB;
            selectedSlot = 'B';
        }
    }
    
    // 5. allocTail 검증 (파일 크기와 일치해야 함)
    long fileSize = storage.size();
    if (header.allocTail > fileSize) {
        // 마지막 커밋 후 추가 데이터가 손실됨
        // 이는 정상 - allocTail까지만 유효
        log.warn("File truncated: header.allocTail={}, fileSize={}", 
                 header.allocTail, fileSize);
    }
    
    log.info("Recovered with slot={}, seqNo={}", selectedSlot, header.seqNo);
    return header;
}
```

---

## 9. 코덱 시스템 구현

### 9.1 코덱 레지스트리

```java
/**
 * 코덱 레지스트리 구현
 */
public class FxCodecRegistryImpl implements FxCodecRegistry {
    private final ConcurrentHashMap<Class<?>, FxCodec<?>> byType = 
        new ConcurrentHashMap<>();
    private final ConcurrentHashMap<String, Map<Integer, FxCodec<?>>> byIdVersion = 
        new ConcurrentHashMap<>();
    
    @Override
    @SuppressWarnings("unchecked")
    public <T> void register(Class<T> type, FxCodec<T> codec) {
        // 타입 중복 체크
        if (byType.putIfAbsent(type, codec) != null) {
            throw new FxException(
                "Codec already registered for type: " + type.getName(),
                ILLEGAL_ARGUMENT
            );
        }
        
        // ID/버전으로도 등록
        byIdVersion.computeIfAbsent(codec.id(), k -> new ConcurrentHashMap<>())
                   .put(codec.version(), codec);
    }
    
    @Override
    @SuppressWarnings("unchecked")
    public <T> FxCodec<T> get(Class<T> type) {
        FxCodec<?> codec = byType.get(type);
        if (codec == null) {
            throw new FxException(
                "No codec registered for type: " + type.getName(),
                CODEC_NOT_FOUND
            );
        }
        return (FxCodec<T>) codec;
    }
    
    @Override
    public FxCodec<?> getById(String codecId, int version) {
        Map<Integer, FxCodec<?>> versions = byIdVersion.get(codecId);
        if (versions == null) {
            return null;
        }
        return versions.get(version);
    }
}
```

### 9.2 내장 코덱 구현

```java
/**
 * I64 코덱 (Long, Integer, Short, Byte 통합)
 */
public class I64Codec implements FxCodec<Long> {
    public static final I64Codec INSTANCE = new I64Codec();
    
    @Override
    public String id() { return "fx:i64"; }
    
    @Override
    public int version() { return 1; }
    
    @Override
    public byte[] encode(Long value) {
        byte[] buf = new byte[8];
        long v = value;
        // Little-endian 저장
        for (int i = 0; i < 8; i++) {
            buf[i] = (byte)(v >>> (i * 8));
        }
        return buf;
    }
    
    @Override
    public Long decode(byte[] bytes) {
        if (bytes.length != 8) {
            throw new IllegalArgumentException("I64 requires 8 bytes");
        }
        long v = 0;
        for (int i = 0; i < 8; i++) {
            v |= (long)(bytes[i] & 0xFF) << (i * 8);
        }
        return v;
    }
    
    @Override
    public int compareBytes(byte[] a, byte[] b) {
        // Signed long comparison
        long va = decode(a);
        long vb = decode(b);
        return Long.compare(va, vb);
    }
    
    @Override
    public boolean equalsBytes(byte[] a, byte[] b) {
        return Arrays.equals(a, b);
    }
    
    @Override
    public int hashBytes(byte[] bytes) {
        return Arrays.hashCode(bytes);
    }
}

/**
 * String 코덱 (UTF-8)
 */
public class StringCodec implements FxCodec<String> {
    public static final StringCodec INSTANCE = new StringCodec();
    
    @Override
    public String id() { return "fx:string:utf8"; }
    
    @Override
    public int version() { return 1; }
    
    @Override
    public byte[] encode(String value) {
        return value.getBytes(StandardCharsets.UTF_8);
    }
    
    @Override
    public String decode(byte[] bytes) {
        return new String(bytes, StandardCharsets.UTF_8);
    }
    
    @Override
    public int compareBytes(byte[] a, byte[] b) {
        // Unsigned lexicographic (UTF-8 바이트 순서)
        int len = Math.min(a.length, b.length);
        for (int i = 0; i < len; i++) {
            int ua = a[i] & 0xFF;
            int ub = b[i] & 0xFF;
            if (ua != ub) return ua - ub;
        }
        return Integer.compare(a.length, b.length);
    }
    
    @Override
    public boolean equalsBytes(byte[] a, byte[] b) {
        return Arrays.equals(a, b);
    }
    
    @Override
    public int hashBytes(byte[] bytes) {
        return Arrays.hashCode(bytes);
    }
}

/**
 * Bytes 코덱 (길이 우선 정렬)
 */
public class BytesCodec implements FxCodec<byte[]> {
    public static final BytesCodec INSTANCE = new BytesCodec();
    
    @Override
    public String id() { return "fx:bytes:lenlex"; }
    
    @Override
    public int version() { return 1; }
    
    @Override
    public byte[] encode(byte[] value) {
        // 복사하여 반환 (불변성 보장)
        return Arrays.copyOf(value, value.length);
    }
    
    @Override
    public byte[] decode(byte[] bytes) {
        // 복사하여 반환
        return Arrays.copyOf(bytes, bytes.length);
    }
    
    @Override
    public int compareBytes(byte[] a, byte[] b) {
        // 길이 우선
        if (a.length != b.length) {
            return Integer.compare(a.length, b.length);
        }
        // 길이가 같으면 unsigned lexicographic
        for (int i = 0; i < a.length; i++) {
            int ua = a[i] & 0xFF;
            int ub = b[i] & 0xFF;
            if (ua != ub) return ua - ub;
        }
        return 0;
    }
    
    @Override
    public boolean equalsBytes(byte[] a, byte[] b) {
        return Arrays.equals(a, b);
    }
    
    @Override
    public int hashBytes(byte[] bytes) {
        return Arrays.hashCode(bytes);
    }
}

/**
 * F64 코덱 (Double, Float 통합)
 */
public class F64Codec implements FxCodec<Double> {
    public static final F64Codec INSTANCE = new F64Codec();
    
    @Override
    public String id() { return "fx:f64"; }
    
    @Override
    public int version() { return 1; }
    
    @Override
    public byte[] encode(Double value) {
        byte[] buf = new byte[8];
        long bits = Double.doubleToRawLongBits(value);
        // Little-endian
        for (int i = 0; i < 8; i++) {
            buf[i] = (byte)(bits >>> (i * 8));
        }
        return buf;
    }
    
    @Override
    public Double decode(byte[] bytes) {
        if (bytes.length != 8) {
            throw new IllegalArgumentException("F64 requires 8 bytes");
        }
        long bits = 0;
        for (int i = 0; i < 8; i++) {
            bits |= (long)(bytes[i] & 0xFF) << (i * 8);
        }
        return Double.longBitsToDouble(bits);
    }
    
    @Override
    public int compareBytes(byte[] a, byte[] b) {
        // Double.compare 사용 (총순서: -0.0 < +0.0, NaN은 최대)
        double va = decode(a);
        double vb = decode(b);
        return Double.compare(va, vb);
    }
    
    @Override
    public boolean equalsBytes(byte[] a, byte[] b) {
        return Arrays.equals(a, b);
    }
    
    @Override
    public int hashBytes(byte[] bytes) {
        return Arrays.hashCode(bytes);
    }
}
```

### 9.3 NumberMode 처리

```java
/**
 * NumberMode에 따른 코덱 해석
 */
public class NumberModeCodecAdapter {
    private final NumberMode mode;
    private final FxCodecRegistry registry;
    
    /**
     * 타입에 맞는 코덱 반환 (CANONICAL 모드에서 정규화)
     */
    @SuppressWarnings("unchecked")
    public <T> FxCodec<T> getCodec(Class<T> type) {
        if (mode == NumberMode.CANONICAL) {
            // 정수 타입 정규화
            if (type == Byte.class || type == Short.class || 
                type == Integer.class || type == Long.class) {
                return (FxCodec<T>) new CanonicalIntegerCodec<>(type);
            }
            // 실수 타입 정규화
            if (type == Float.class || type == Double.class) {
                return (FxCodec<T>) new CanonicalFloatCodec<>(type);
            }
        }
        
        return registry.get(type);
    }
    
    /**
     * CANONICAL 정수 코덱 래퍼
     */
    private class CanonicalIntegerCodec<T extends Number> implements FxCodec<T> {
        private final Class<T> type;
        
        @Override
        public String id() { return "fx:i64"; }
        
        @Override
        public int version() { return 1; }
        
        @Override
        public byte[] encode(T value) {
            return I64Codec.INSTANCE.encode(value.longValue());
        }
        
        @Override
        @SuppressWarnings("unchecked")
        public T decode(byte[] bytes) {
            long v = I64Codec.INSTANCE.decode(bytes);
            
            if (type == Long.class) return (T) Long.valueOf(v);
            if (type == Integer.class) {
                if (v < Integer.MIN_VALUE || v > Integer.MAX_VALUE) {
                    throw new ArithmeticException("Value out of Integer range");
                }
                return (T) Integer.valueOf((int) v);
            }
            if (type == Short.class) {
                if (v < Short.MIN_VALUE || v > Short.MAX_VALUE) {
                    throw new ArithmeticException("Value out of Short range");
                }
                return (T) Short.valueOf((short) v);
            }
            if (type == Byte.class) {
                if (v < Byte.MIN_VALUE || v > Byte.MAX_VALUE) {
                    throw new ArithmeticException("Value out of Byte range");
                }
                return (T) Byte.valueOf((byte) v);
            }
            
            throw new IllegalStateException("Unknown type: " + type);
        }
        
        @Override
        public int compareBytes(byte[] a, byte[] b) {
            return I64Codec.INSTANCE.compareBytes(a, b);
        }
        
        // ... equals, hash는 I64Codec에 위임
    }
}
```

---

## 10. 컴팩션 알고리즘

### 10.1 Dead 바이트 추정

```java
/**
 * Dead 바이트 추정 (FAST 모드)
 */
public Stats computeStatsFast() {
    long fileBytes = storage.size();
    long allocTail = committedHeader.allocTail;
    
    // 도달 가능한 바이트 추정
    // = 헤더 영역 + (도달 가능한 페이지 수 × pageSize) + (추정 레코드 크기)
    
    long headerAreaBytes = 12288;  // Superblock + 2 headers
    
    // 컬렉션 수와 평균 트리 깊이로 페이지 수 추정
    int collectionCount = listCollections().size();
    
    // 대략적 추정:
    // - Catalog: log2(collectionCount) * 2 페이지
    // - State: log2(collectionCount) * 2 페이지
    // - 각 컬렉션: 평균 log2(avgSize) * 2 페이지
    
    long estimatedPages = 0;
    estimatedPages += Math.max(1, (long)(Math.log(collectionCount + 1) / Math.log(2)) * 2);
    estimatedPages += Math.max(1, (long)(Math.log(collectionCount + 1) / Math.log(2)) * 2);
    
    for (CollectionInfo ci : listCollections()) {
        CollectionState state = stateTree.find(ci.collectionId);
        long size = state.size;
        estimatedPages += Math.max(1, (long)(Math.log(size + 1) / Math.log(2)) * 2);
    }
    
    long liveBytesEstimate = headerAreaBytes + estimatedPages * pageSize;
    long deadBytesEstimate = Math.max(0, allocTail - liveBytesEstimate);
    double deadRatio = allocTail > 0 ? (double) deadBytesEstimate / allocTail : 0;
    
    return new Stats(fileBytes, liveBytesEstimate, deadBytesEstimate, 
                     deadRatio, collectionCount);
}
```

### 10.2 Dead 바이트 정확 계산 (DEEP 모드)

```java
/**
 * Dead 바이트 정확 계산 (DEEP 모드)
 */
public Stats computeStatsDeep() {
    long fileBytes = storage.size();
    
    // 도달 가능한 모든 페이지와 레코드 수집
    Set<Long> reachablePageIds = new HashSet<>();
    Set<Long> reachableRecordOffsets = new HashSet<>();
    
    // BFS로 모든 도달 가능 객체 탐색
    Queue<Long> pageQueue = new LinkedList<>();
    
    // Catalog 루트
    if (committedHeader.catalogRootPageId != 0) {
        pageQueue.add(committedHeader.catalogRootPageId);
    }
    
    // State 루트
    if (committedHeader.stateRootPageId != 0) {
        pageQueue.add(committedHeader.stateRootPageId);
    }
    
    while (!pageQueue.isEmpty()) {
        long pageId = pageQueue.poll();
        if (reachablePageIds.contains(pageId)) continue;
        reachablePageIds.add(pageId);
        
        Page page = readPage(pageId);
        
        switch (page.getType()) {
            case BTREE_INTERNAL:
                for (int i = 0; i < page.getChildCount(); i++) {
                    pageQueue.add(page.getChild(i));
                }
                break;
                
            case BTREE_LEAF:
                for (int i = 0; i < page.getEntryCount(); i++) {
                    long valueRef = page.getValueRef(i);
                    if (valueRef != 0) {
                        reachableRecordOffsets.add(valueRef);
                    }
                }
                break;
                
            case OST_INTERNAL:
                for (int i = 0; i < page.getChildCount(); i++) {
                    pageQueue.add(page.getChild(i));
                }
                break;
                
            case OST_LEAF:
                for (int i = 0; i < page.getElemCount(); i++) {
                    long valueRef = page.getElemRef(i);
                    if (valueRef != 0) {
                        reachableRecordOffsets.add(valueRef);
                    }
                }
                break;
        }
    }
    
    // State에서 참조하는 컬렉션 루트들도 탐색
    // (State 리프의 CollectionState.rootPageId)
    for (Long recordOffset : new ArrayList<>(reachableRecordOffsets)) {
        // State 레코드에서 rootPageId 추출하여 페이지 탐색
        // ...
    }
    
    // Live 바이트 계산
    long headerAreaBytes = 12288;
    long livePageBytes = reachablePageIds.size() * pageSize;
    long liveRecordBytes = 0;
    
    for (long offset : reachableRecordOffsets) {
        int recordSize = readRecordSize(offset);
        liveRecordBytes += recordSize;
    }
    
    long liveBytesEstimate = headerAreaBytes + livePageBytes + liveRecordBytes;
    long deadBytesEstimate = committedHeader.allocTail - liveBytesEstimate;
    double deadRatio = committedHeader.allocTail > 0 
        ? (double) deadBytesEstimate / committedHeader.allocTail 
        : 0;
    
    return new Stats(fileBytes, liveBytesEstimate, deadBytesEstimate,
                     deadRatio, listCollections().size());
}
```

### 10.3 컴팩션 구현

```java
/**
 * 컴팩션 구현
 */
public void compactTo(Path newFile) {
    // 1. 사전 조건 검증
    if (batchState.hasPendingChanges()) {
        throw new FxException(
            "Cannot compact with pending changes in BATCH mode",
            ILLEGAL_ARGUMENT
        );
    }
    
    // 2. 대상 파일 생성
    FxOptions targetOptions = FxOptions.defaults()
        .withPageSize(this.pageSize)
        .withCommitMode(CommitMode.AUTO)  // 컴팩션 중에는 AUTO
        .withDurability(Durability.ASYNC);  // 최종에만 SYNC
    
    try (FxStore target = FxStore.open(newFile, targetOptions)) {
        // 3. Catalog 복제
        List<CatalogEntry> entries = catalogTree.scanAll();
        
        for (CatalogEntry entry : entries) {
            // 동일 이름/종류/코덱으로 생성
            switch (entry.kind) {
                case MAP:
                    target.createMap(entry.name, 
                        resolveKeyClass(entry), 
                        resolveValueClass(entry));
                    break;
                case SET:
                    target.createSet(entry.name, resolveValueClass(entry));
                    break;
                case LIST:
                    target.createList(entry.name, resolveValueClass(entry));
                    break;
                case DEQUE:
                    target.createDeque(entry.name, resolveValueClass(entry));
                    break;
            }
        }
        
        // 4. 데이터 복제
        for (CatalogEntry entry : entries) {
            copyCollectionData(entry, target);
        }
        
        // 5. 최종 동기화
        if (durability == Durability.SYNC) {
            target.storage.force(true);
        }
    }
}

/**
 * 컬렉션 데이터 복제
 */
private void copyCollectionData(CatalogEntry entry, FxStore target) {
    CollectionState state = stateTree.find(entry.collectionId);
    
    switch (entry.kind) {
        case MAP:
            copyMapData(entry.name, state.rootPageId, target);
            break;
        case SET:
            copySetData(entry.name, state.rootPageId, target);
            break;
        case LIST:
            copyListData(entry.name, state.rootPageId, state.size, target);
            break;
        case DEQUE:
            copyDequeData(entry.name, state, target);
            break;
    }
}

/**
 * Map 데이터 복제
 */
private void copyMapData(String name, long rootPageId, FxStore target) {
    NavigableMap<Object, Object> srcMap = openMapRaw(name);
    NavigableMap<Object, Object> dstMap = target.openMapRaw(name);
    
    // 리프 순회로 정렬 순서 유지
    BTreeCursor cursor = btree.cursor(rootPageId, null, null);
    while (cursor.hasNext()) {
        LeafEntry entry = cursor.next();
        
        Object key = keyCodec.decode(entry.key);
        Object value = valueCodec.decode(readValueRecord(entry.valueRef));
        
        dstMap.put(key, value);
    }
}

/**
 * List 데이터 복제
 */
private void copyListData(String name, long rootPageId, long size, FxStore target) {
    List<Object> srcList = openListRaw(name);
    List<Object> dstList = target.openListRaw(name);
    
    // 인덱스 순서로 순회
    for (int i = 0; i < size; i++) {
        Object elem = srcList.get(i);
        dstList.add(elem);
    }
}

/**
 * Deque 데이터 복제
 */
private void copyDequeData(String name, CollectionState state, FxStore target) {
    Deque<Object> srcDeque = openDequeRaw(name);
    Deque<Object> dstDeque = target.openDequeRaw(name);
    
    // head → tail 순서로 순회
    for (Object elem : srcDeque) {
        dstDeque.addLast(elem);
    }
}
```

---

## 11. 동시성과 락 전략

### 11.1 단일 Writer 모델

```java
/**
 * 파일 락 획득
 */
public class FileLockManager {
    private FileLock exclusiveLock;
    
    public void acquireWriterLock(FileChannel channel, FileLockMode mode) {
        if (mode == FileLockMode.NONE) {
            return;
        }
        
        try {
            // 전체 파일에 대한 배타적 잠금
            exclusiveLock = channel.tryLock(0, Long.MAX_VALUE, false);
            
            if (exclusiveLock == null) {
                throw new FxException(
                    "Could not acquire exclusive lock - another writer exists",
                    LOCK_FAILED
                );
            }
        } catch (OverlappingFileLockException e) {
            throw new FxException(
                "File already locked by this JVM",
                LOCK_FAILED
            );
        } catch (IOException e) {
            throw new FxException("Lock acquisition failed", IO);
        }
    }
    
    public void release() {
        if (exclusiveLock != null) {
            try {
                exclusiveLock.release();
            } catch (IOException e) {
                // 로그만 기록, 예외 던지지 않음
                log.warn("Failed to release file lock", e);
            }
            exclusiveLock = null;
        }
    }
}
```

### 11.2 스레드 안전성 구현

```java
/**
 * Store 레벨 동기화
 */
public class FxStoreImpl implements FxStore {
    // 읽기/쓰기 락
    private final ReadWriteLock rwLock = new ReentrantReadWriteLock();
    private final Lock readLock = rwLock.readLock();
    private final Lock writeLock = rwLock.writeLock();
    
    // 읽기 연산
    public boolean exists(String name) {
        readLock.lock();
        try {
            checkNotClosed();
            return catalogCache.contains(name);
        } finally {
            readLock.unlock();
        }
    }
    
    // 쓰기 연산
    public boolean drop(String name) {
        writeLock.lock();
        try {
            checkNotClosed();
            
            CatalogEntry entry = catalogTree.find(name);
            if (entry == null) {
                throw new FxException("Collection not found: " + name, NOT_FOUND);
            }
            
            // Catalog에서 삭제
            long newCatalogRoot = catalogTree.delete(name);
            
            // State에서 삭제
            long newStateRoot = stateTree.delete(entry.collectionId);
            
            // 루트 갱신
            recordCatalogChange(newCatalogRoot);
            recordStateChange(newStateRoot);
            
            // AUTO 모드면 즉시 커밋
            if (commitMode == CommitMode.AUTO) {
                commit();
            }
            
            // 캐시 무효화
            catalogCache.remove(name);
            
            return true;
        } finally {
            writeLock.unlock();
        }
    }
    
    // close는 특별 처리
    public void close() {
        writeLock.lock();
        try {
            if (closed) return;
            
            // OnClosePolicy 처리
            if (commitMode == CommitMode.BATCH && batchState.hasPendingChanges()) {
                switch (onClosePolicy) {
                    case ERROR:
                        closed = true;
                        releaseResources();
                        throw new FxException(
                            "Uncommitted changes exist",
                            ILLEGAL_ARGUMENT
                        );
                    case COMMIT:
                        commit();
                        break;
                    case ROLLBACK:
                        rollback();
                        break;
                }
            }
            
            closed = true;
            releaseResources();
        } finally {
            writeLock.unlock();
        }
    }
}
```

### 11.3 컬렉션 핸들 스레드 안전성

```java
/**
 * Map 핸들
 * 
 * 연산은 Store의 락을 통해 동기화됨
 */
public class FxNavigableMap<K, V> implements NavigableMap<K, V> {
    private final FxStoreImpl store;
    private final long collectionId;
    private final FxCodec<K> keyCodec;
    private final FxCodec<V> valueCodec;
    
    @Override
    public V get(Object key) {
        // Store의 readLock 사용
        return store.withReadLock(() -> {
            store.checkNotClosed();
            
            CollectionState state = store.getState(collectionId);
            byte[] keyBytes = keyCodec.encode((K) key);
            
            Long valueRef = btree.find(state.rootPageId, keyBytes);
            if (valueRef == null) return null;
            
            byte[] valueBytes = store.readValueRecord(valueRef);
            return valueCodec.decode(valueBytes);
        });
    }
    
    @Override
    public V put(K key, V value) {
        if (key == null || value == null) {
            throw new NullPointerException();
        }
        
        // Store의 writeLock 사용
        return store.withWriteLock(() -> {
            store.checkNotClosed();
            
            CollectionState state = store.getState(collectionId);
            byte[] keyBytes = keyCodec.encode(key);
            
            // 기존 값 조회 (반환용)
            Long oldValueRef = btree.find(state.rootPageId, keyBytes);
            V oldValue = null;
            if (oldValueRef != null) {
                oldValue = valueCodec.decode(store.readValueRecord(oldValueRef));
            }
            
            // 새 값 기록
            byte[] valueBytes = valueCodec.encode(value);
            long newValueRef = store.writeValueRecord(valueBytes);
            
            // B+Tree 갱신
            long newRoot = btree.insert(state.rootPageId, keyBytes, newValueRef);
            
            // State 갱신
            long newSize = oldValue == null ? state.size + 1 : state.size;
            store.updateState(collectionId, newRoot, newSize, 
                              state.dequeHeadSeq, state.dequeTailSeq);
            
            return oldValue;
        });
    }
}
```

---

## 12. 성능 최적화 기법

### 12.1 페이지 캐시 최적화

```java
/**
 * 계층형 캐시
 */
public class TieredPageCache {
    // Hot 캐시: 자주 접근하는 페이지 (State, Catalog 루트 근처)
    private final LRUCache<Long, byte[]> hotCache;
    
    // Cold 캐시: 일반 페이지
    private final LRUCache<Long, byte[]> coldCache;
    
    // 접근 횟수 추적
    private final Map<Long, AtomicInteger> accessCounts = new ConcurrentHashMap<>();
    
    private static final int HOT_THRESHOLD = 10;  // 10회 이상 접근 시 hot으로 승격
    
    public byte[] get(long pageId) {
        // Hot 캐시 먼저 확인
        byte[] page = hotCache.get(pageId);
        if (page != null) {
            return page;
        }
        
        // Cold 캐시 확인
        page = coldCache.get(pageId);
        if (page != null) {
            // 접근 횟수 증가
            int count = accessCounts
                .computeIfAbsent(pageId, k -> new AtomicInteger())
                .incrementAndGet();
            
            // Hot으로 승격?
            if (count >= HOT_THRESHOLD) {
                coldCache.remove(pageId);
                hotCache.put(pageId, page);
            }
            
            return page;
        }
        
        return null;  // 캐시 미스
    }
    
    public void put(long pageId, byte[] page) {
        // 새 페이지는 cold에 먼저
        coldCache.put(pageId, page);
        accessCounts.put(pageId, new AtomicInteger(1));
    }
}
```

### 12.2 배치 쓰기 최적화

```java
/**
 * 배치 쓰기 버퍼
 */
public class WriteBuffer {
    private final Storage storage;
    private final ByteBuffer buffer;
    private long bufferStartOffset;
    private int bufferPosition;
    
    private static final int BUFFER_SIZE = 256 * 1024;  // 256KB
    
    public WriteBuffer(Storage storage) {
        this.storage = storage;
        this.buffer = ByteBuffer.allocateDirect(BUFFER_SIZE);
        this.bufferStartOffset = -1;
    }
    
    public void write(long offset, byte[] data) {
        // 버퍼가 비어있거나 연속 쓰기가 아니면 flush
        if (bufferStartOffset < 0) {
            bufferStartOffset = offset;
            bufferPosition = 0;
        } else if (bufferStartOffset + bufferPosition != offset) {
            flush();
            bufferStartOffset = offset;
            bufferPosition = 0;
        }
        
        // 버퍼에 공간이 없으면 flush
        if (bufferPosition + data.length > BUFFER_SIZE) {
            flush();
            bufferStartOffset = offset;
            bufferPosition = 0;
        }
        
        // 버퍼에 쓰기
        buffer.position(bufferPosition);
        buffer.put(data);
        bufferPosition += data.length;
    }
    
    public void flush() {
        if (bufferPosition > 0) {
            buffer.flip();
            byte[] data = new byte[bufferPosition];
            buffer.get(data);
            storage.write(bufferStartOffset, data, 0, data.length);
            buffer.clear();
            bufferPosition = 0;
            bufferStartOffset = -1;
        }
    }
}
```

### 12.3 Bulk Load 최적화

```java
/**
 * 대량 삽입 최적화 (정렬된 데이터)
 */
public long bulkLoad(Iterator<Entry<byte[], Long>> sortedEntries) {
    if (!sortedEntries.hasNext()) {
        return 0;  // 빈 트리
    }
    
    // 1. 리프 페이지들을 순차적으로 생성
    List<LeafPage> leaves = new ArrayList<>();
    LeafPage currentLeaf = createEmptyLeaf();
    
    while (sortedEntries.hasNext()) {
        Entry<byte[], Long> entry = sortedEntries.next();
        byte[] entryBlob = encodeLeafEntry(entry.getKey(), entry.getValue());
        
        if (!currentLeaf.hasSpaceFor(entryBlob)) {
            leaves.add(currentLeaf);
            currentLeaf = createEmptyLeaf();
        }
        
        currentLeaf.appendEntry(entryBlob);
    }
    leaves.add(currentLeaf);
    
    // 2. 리프 체인 연결 및 저장
    List<Long> leafPageIds = new ArrayList<>();
    for (int i = 0; i < leaves.size(); i++) {
        LeafPage leaf = leaves.get(i);
        if (i < leaves.size() - 1) {
            // nextLeafPageId는 아직 모름 - 일단 0으로
        }
        long pageId = writePage(leaf);
        leafPageIds.add(pageId);
    }
    
    // 3. nextLeaf 연결 (역순으로)
    for (int i = leaves.size() - 2; i >= 0; i--) {
        LeafPage leaf = leaves.get(i);
        leaf.setNextLeafPageId(leafPageIds.get(i + 1));
        // 페이지 재작성 (또는 in-place 수정 - append-only 위반 주의)
    }
    
    // 4. 하위 → 상위 순서로 internal 노드 생성
    List<Long> currentLevel = leafPageIds;
    List<byte[]> separatorKeys = extractSeparatorKeys(leaves);
    
    while (currentLevel.size() > 1) {
        List<Long> nextLevel = new ArrayList<>();
        List<byte[]> nextSeparators = new ArrayList<>();
        
        // B+Tree 차수에 맞게 internal 노드 생성
        // ...
        
        currentLevel = nextLevel;
        separatorKeys = nextSeparators;
    }
    
    return currentLevel.get(0);  // 루트 pageId
}
```

### 12.4 Iterator 최적화

```java
/**
 * Prefetch Iterator
 */
public class PrefetchingBTreeCursor implements Iterator<LeafEntry> {
    private final BPlusTree tree;
    private Page currentLeaf;
    private int currentIndex;
    
    // Prefetch 버퍼
    private final Queue<Page> prefetchBuffer = new ArrayDeque<>();
    private static final int PREFETCH_SIZE = 4;
    
    // 백그라운드 prefetch
    private final ExecutorService prefetchExecutor;
    
    @Override
    public LeafEntry next() {
        LeafEntry entry = new LeafEntry(
            currentLeaf.getKey(currentIndex),
            currentLeaf.getValueRef(currentIndex)
        );
        
        currentIndex++;
        advanceIfNeeded();
        
        return entry;
    }
    
    private void advanceIfNeeded() {
        if (currentLeaf != null && currentIndex >= currentLeaf.getEntryCount()) {
            // 다음 리프로 이동
            if (!prefetchBuffer.isEmpty()) {
                currentLeaf = prefetchBuffer.poll();
            } else {
                long nextPageId = currentLeaf.getNextLeafPageId();
                if (nextPageId == 0) {
                    currentLeaf = null;
                } else {
                    currentLeaf = tree.readPage(nextPageId);
                }
            }
            currentIndex = 0;
            
            // Prefetch 트리거
            triggerPrefetch();
        }
    }
    
    private void triggerPrefetch() {
        if (prefetchBuffer.size() < PREFETCH_SIZE / 2 && currentLeaf != null) {
            long nextPageId = currentLeaf.getNextLeafPageId();
            if (nextPageId != 0) {
                prefetchExecutor.submit(() -> {
                    // 다음 몇 개의 리프를 미리 로드
                    long pageId = nextPageId;
                    for (int i = 0; i < PREFETCH_SIZE && pageId != 0; i++) {
                        Page page = tree.readPage(pageId);
                        synchronized (prefetchBuffer) {
                            prefetchBuffer.offer(page);
                        }
                        pageId = page.getNextLeafPageId();
                    }
                });
            }
        }
    }
}
```

---

## 13. 테스트 및 검증 전략

### 13.1 단위 테스트 체크리스트

```java
/**
 * B+Tree 테스트
 */
public class BPlusTreeTest {
    @Test
    void testInsertAndFind() {
        // 단일 삽입/조회
    }
    
    @Test
    void testInsertMany() {
        // 대량 삽입 (split 발생)
    }
    
    @Test
    void testInsertSorted() {
        // 정렬된 순서로 삽입
    }
    
    @Test
    void testInsertReverseSorted() {
        // 역순으로 삽입
    }
    
    @Test
    void testInsertRandom() {
        // 랜덤 순서로 삽입
    }
    
    @Test
    void testDelete() {
        // 삭제 후 조회
    }
    
    @Test
    void testDeleteAll() {
        // 모든 키 삭제
    }
    
    @Test
    void testCursor() {
        // 전체 순회
    }
    
    @Test
    void testCursorRange() {
        // 범위 순회
    }
    
    @Test
    void testDuplicateKey() {
        // 중복 키 삽입 (replace)
    }
}

/**
 * OST 테스트
 */
public class OrderStatisticTreeTest {
    @Test
    void testGetByIndex() {
        // 인덱스 조회
    }
    
    @Test
    void testInsertAtBeginning() {
        // 처음에 삽입
    }
    
    @Test
    void testInsertAtEnd() {
        // 끝에 삽입
    }
    
    @Test
    void testInsertAtMiddle() {
        // 중간에 삽입
    }
    
    @Test
    void testRemoveFromBeginning() {
        // 처음에서 삭제
    }
    
    @Test
    void testRemoveFromMiddle() {
        // 중간에서 삭제
    }
    
    @Test
    void testCountConsistency() {
        // subtreeCount 일관성 검증
    }
}
```

### 13.2 통합 테스트

```java
/**
 * 참조 구현과의 동등성 테스트
 */
public class CollectionEquivalenceTest {
    private FxStore store;
    private NavigableMap<Long, String> fxMap;
    private NavigableMap<Long, String> refMap;  // TreeMap
    
    @BeforeEach
    void setup() {
        store = FxStore.openMemory();
        fxMap = store.createMap("test", Long.class, String.class);
        refMap = new TreeMap<>();
    }
    
    @Test
    void testRandomOperations() {
        Random rand = new Random(42);
        
        for (int i = 0; i < 10000; i++) {
            int op = rand.nextInt(100);
            
            if (op < 60) {
                // put
                long key = rand.nextLong();
                String value = "value-" + i;
                fxMap.put(key, value);
                refMap.put(key, value);
            } else if (op < 80) {
                // get
                long key = rand.nextLong();
                assertEquals(refMap.get(key), fxMap.get(key));
            } else if (op < 95) {
                // remove
                if (!refMap.isEmpty()) {
                    long key = refMap.firstKey();
                    assertEquals(refMap.remove(key), fxMap.remove(key));
                }
            } else {
                // size
                assertEquals(refMap.size(), fxMap.size());
            }
        }
        
        // 최종 내용 일치 확인
        assertEquals(refMap.size(), fxMap.size());
        for (var entry : refMap.entrySet()) {
            assertEquals(entry.getValue(), fxMap.get(entry.getKey()));
        }
    }
}
```

### 13.3 크래시 테스트

```java
/**
 * 크래시 시뮬레이션 테스트
 */
public class CrashRecoveryTest {
    @Test
    void testCrashBeforeHeaderWrite() throws Exception {
        Path file = tempDir.resolve("test.fx");
        
        // 1. 초기 데이터 생성
        try (FxStore store = FxStore.open(file)) {
            store.createMap("m", Long.class, String.class).put(1L, "a");
        }
        
        // 2. 크래시 시뮬레이션: 데이터는 쓰되 헤더는 안 씀
        try (CrashSimulatingStore store = new CrashSimulatingStore(file)) {
            store.setFailBeforeHeader(true);
            
            assertThrows(SimulatedCrashException.class, () -> {
                store.openMap("m", Long.class, String.class).put(2L, "b");
            });
        }
        
        // 3. 복구 후 검증
        try (FxStore store = FxStore.open(file)) {
            NavigableMap<Long, String> m = store.openMap("m", Long.class, String.class);
            assertEquals("a", m.get(1L));
            assertNull(m.get(2L));  // 크래시로 인해 커밋 안 됨
        }
    }
    
    @Test
    void testCrashAfterDataForce() throws Exception {
        // 데이터 force 후, 헤더 쓰기 전 크래시
        // → 이전 상태로 복구
    }
    
    @Test
    void testCrashDuringHeaderWrite() throws Exception {
        // 헤더 쓰기 중간에 크래시
        // → CRC 검증으로 무효 헤더 감지
    }
    
    @Test
    void testBothHeadersCorrupted() throws Exception {
        // 두 헤더 슬롯 모두 손상
        // → CORRUPTION 예외
    }
}
```

### 13.4 퍼즈 테스트

```java
/**
 * 퍼즈 테스트
 */
public class FuzzTest {
    @Test
    void fuzzBPlusTree() {
        byte[][] keys = generateRandomKeys(1000, 1, 100);
        long[] values = generateRandomValues(1000);
        
        BPlusTree tree = new BPlusTree(...);
        Map<ByteArrayWrapper, Long> reference = new HashMap<>();
        
        Random rand = new Random();
        
        for (int i = 0; i < 100000; i++) {
            int op = rand.nextInt(100);
            int idx = rand.nextInt(keys.length);
            
            if (op < 70) {
                // insert
                tree.insert(keys[idx], values[idx]);
                reference.put(new ByteArrayWrapper(keys[idx]), values[idx]);
            } else {
                // delete
                tree.delete(keys[idx]);
                reference.remove(new ByteArrayWrapper(keys[idx]));
            }
            
            // 주기적 검증
            if (i % 1000 == 0) {
                verifyTreeConsistency(tree, reference);
            }
        }
    }
    
    void verifyTreeConsistency(BPlusTree tree, Map<ByteArrayWrapper, Long> reference) {
        // 모든 참조 키가 트리에 있는지
        for (var entry : reference.entrySet()) {
            Long found = tree.find(entry.getKey().data);
            assertEquals(entry.getValue(), found, 
                "Key not found: " + Arrays.toString(entry.getKey().data));
        }
        
        // 트리의 모든 키가 참조에 있는지
        BTreeCursor cursor = tree.cursor(null, null);
        int count = 0;
        while (cursor.hasNext()) {
            LeafEntry e = cursor.next();
            assertTrue(reference.containsKey(new ByteArrayWrapper(e.key)),
                "Extra key in tree: " + Arrays.toString(e.key));
            count++;
        }
        
        assertEquals(reference.size(), count, "Size mismatch");
    }
}
```

---

## 14. 구현 로드맵

### 14.1 Phase 1: 기반 인프라 (1-2주)

```
Week 1:
□ Varint (LEB128) encode/decode
□ Little-endian read/write utilities
□ CRC32C implementation (java.util.zip.CRC32C)
□ alignUp utility
□ Storage interface + FileStorage + MemoryStorage

Week 2:
□ Superblock encode/decode/verify
□ CommitHeader encode/decode
□ Header slot selection logic
□ Basic file open/close
```

### 14.2 Phase 2: 페이지 시스템 (1-2주)

```
Week 3:
□ Page header encode/decode
□ Slotted page implementation
□ PageCache (LRU)
□ Allocator

Week 4:
□ BTREE_LEAF page format
□ BTREE_INTERNAL page format
□ Page CRC verification
□ Basic page read/write
```

### 14.3 Phase 3: B+Tree (2-3주)

```
Week 5:
□ B+Tree find
□ B+Tree insert (no split)
□ Leaf split
□ Internal split

Week 6:
□ B+Tree delete (no merge)
□ COW propagation
□ BTreeCursor implementation

Week 7:
□ ValueRecord format
□ Value record read/write
□ Integration: B+Tree + ValueRecord
```

### 14.4 Phase 4: Catalog/State (1주)

```
Week 8:
□ CatalogEntry encode/decode
□ CollectionState encode/decode
□ CatalogTree (B+Tree 재사용)
□ StateTree (B+Tree 재사용)
□ Basic create/open/drop
```

### 14.5 Phase 5: 컬렉션 (2주)

```
Week 9:
□ FxNavigableMap implementation
□ FxNavigableSet implementation
□ Codec system
□ Built-in codecs (I64, F64, STRING, BYTES)

Week 10:
□ Deque sequence encoding
□ FxDeque implementation
□ BATCH mode (pending roots)
□ commit/rollback
```

### 14.6 Phase 6: List (OST) (2주)

```
Week 11:
□ OST_INTERNAL page format
□ OST_LEAF page format
□ OST get (count-based traversal)
□ OST insert

Week 12:
□ OST delete
□ OST split
□ FxList implementation
□ Count consistency verification
```

### 14.7 Phase 7: 운영 기능 (1-2주)

```
Week 13:
□ rename
□ list
□ stats (FAST/DEEP)
□ verify

Week 14:
□ compactTo
□ OnClosePolicy handling
□ FileLockMode
□ Thread safety audit
```

### 14.8 Phase 8: 테스트 및 안정화 (2주)

```
Week 15:
□ Unit tests for all components
□ Integration tests
□ Equivalence tests vs TreeMap/ArrayList

Week 16:
□ Crash recovery tests
□ Fuzz tests
□ Performance benchmarks
□ Documentation
```

---

## 부록 A: 체크리스트

### A.1 구현 전 체크리스트

- [ ] SRS v0.3 완전히 이해
- [ ] API 명세서 완전히 이해
- [ ] 모든 불변식 숙지
- [ ] 테스트 전략 수립

### A.2 각 컴포넌트 체크리스트

**Storage:**
- [ ] read/write 정확성
- [ ] force 동작
- [ ] 에러 처리

**Allocator:**
- [ ] 페이지 정렬
- [ ] 레코드 정렬
- [ ] BATCH 모드 지원

**B+Tree:**
- [ ] find 정확성
- [ ] insert + split
- [ ] delete
- [ ] COW 전파
- [ ] cursor 순회

**OST:**
- [ ] get by index
- [ ] insert at index
- [ ] remove at index
- [ ] count 일관성

**커밋:**
- [ ] SYNC force 순서
- [ ] BATCH pending 관리
- [ ] 크래시 복구

### A.3 릴리스 전 체크리스트

- [ ] 모든 단위 테스트 통과
- [ ] 통합 테스트 통과
- [ ] 크래시 테스트 통과
- [ ] 퍼즈 테스트 통과
- [ ] 성능 벤치마크 완료
- [ ] API 문서화 완료
- [ ] 코드 리뷰 완료

---

## 부록 B: 참고 자료

1. **B+Tree:**
   - "Database Internals" by Alex Petrov
   - SQLite B-Tree implementation

2. **Order-Statistic Tree:**
   - "Introduction to Algorithms" (CLRS), Chapter 14

3. **Copy-on-Write:**
   - LMDB design
   - ZFS COW semantics

4. **Crash Consistency:**
   - "All File Systems Are Not Created Equal" (OSDI 2014)
   - fsync semantics on different platforms

---

*문서 끝*
